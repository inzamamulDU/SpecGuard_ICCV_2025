Tensorboard is enabled. Creating logger.
Model Configuration:

{'H': 256,
 'W': 256,
 'adversarial_loss': 0.001,
 'ber_loss_weight': 0.5,
 'decoder_blocks': 8,
 'decoder_channels': 128,
 'decoder_loss': 1,
 'discriminator_blocks': 8,
 'discriminator_channels': 64,
 'enable_fp16': True,
 'encoder_blocks': 8,
 'encoder_channels': 128,
 'encoder_loss': 0.7,
 'message_length': 128,
 'use_discriminator': True,
 'use_vgg': False,
 'watermark_radius': 50,
 'watermark_value': 1.0}

Noise configuration:

"[Crop(), Cropout(), Dropout(), 'JpegPlaceholder']"

Training train_options:

{'batch_size': 32,
 'experiment_name': 'celebhq-rebuttal',
 'number_of_epochs': 300,
 'runs_folder': './runs',
 'start_epoch': 1,
 'train_folder': '/media/NAS/DATASET/demo/train',
 'validation_folder': '/media/NAS/DATASET/demo/val'}

Starting epoch 1/300
Batch size = 32
Steps in epoch = 15
Epoch: 1/300 Step: 10/15
total_loss          0.5285
encoder_mse         0.0010
decoder_mse         0.3519
ber_loss            0.3519
----------------------------------------
Epoch: 1/300 Step: 15/15
total_loss          0.6022
encoder_mse         0.0010
decoder_mse         0.4010
ber_loss            0.4010
----------------------------------------
Epoch 1 training duration 10.56 sec
----------------------------------------
Running validation for epoch 1/300
total_loss          0.5643
encoder_mse         0.0011
decoder_mse         0.3757
ber_loss            0.3757
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-1.pyt
Saving checkpoint done.

Starting epoch 2/300
Batch size = 32
Steps in epoch = 15
Epoch: 2/300 Step: 10/15
total_loss          0.5280
encoder_mse         0.0009
decoder_mse         0.3516
ber_loss            0.3516
----------------------------------------
Epoch: 2/300 Step: 15/15
total_loss          0.5561
encoder_mse         0.0009
decoder_mse         0.3703
ber_loss            0.3703
----------------------------------------
Epoch 2 training duration 10.38 sec
----------------------------------------
Running validation for epoch 2/300
total_loss          0.5636
encoder_mse         0.0011
decoder_mse         0.3752
ber_loss            0.3752
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-2.pyt
Saving checkpoint done.

Starting epoch 3/300
Batch size = 32
Steps in epoch = 15
Epoch: 3/300 Step: 10/15
total_loss          0.4474
encoder_mse         0.0009
decoder_mse         0.2978
ber_loss            0.2978
----------------------------------------
Epoch: 3/300 Step: 15/15
total_loss          0.5000
encoder_mse         0.0010
decoder_mse         0.3329
ber_loss            0.3329
----------------------------------------
Epoch 3 training duration 9.73 sec
----------------------------------------
Running validation for epoch 3/300
total_loss          0.4718
encoder_mse         0.0011
decoder_mse         0.3140
ber_loss            0.3140
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-3.pyt
Saving checkpoint done.

Starting epoch 4/300
Batch size = 32
Steps in epoch = 15
Epoch: 4/300 Step: 10/15
total_loss          0.6777
encoder_mse         0.0010
decoder_mse         0.4513
ber_loss            0.4513
----------------------------------------
Epoch: 4/300 Step: 15/15
total_loss          0.6511
encoder_mse         0.0010
decoder_mse         0.4336
ber_loss            0.4336
----------------------------------------
Epoch 4 training duration 10.24 sec
----------------------------------------
Running validation for epoch 4/300
total_loss          0.6583
encoder_mse         0.0011
decoder_mse         0.4383
ber_loss            0.4383
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-4.pyt
Saving checkpoint done.

Starting epoch 5/300
Batch size = 32
Steps in epoch = 15
Epoch: 5/300 Step: 10/15
total_loss          0.5279
encoder_mse         0.0009
decoder_mse         0.3515
ber_loss            0.3515
----------------------------------------
Epoch: 5/300 Step: 15/15
total_loss          0.5982
encoder_mse         0.0009
decoder_mse         0.3984
ber_loss            0.3984
----------------------------------------
Epoch 5 training duration 10.27 sec
----------------------------------------
Running validation for epoch 5/300
total_loss          0.5667
encoder_mse         0.0011
decoder_mse         0.3773
ber_loss            0.3773
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-5.pyt
Saving checkpoint done.

Starting epoch 6/300
Batch size = 32
Steps in epoch = 15
Epoch: 6/300 Step: 10/15
total_loss          0.4538
encoder_mse         0.0009
decoder_mse         0.3021
ber_loss            0.3021
----------------------------------------
Epoch: 6/300 Step: 15/15
total_loss          0.4533
encoder_mse         0.0009
decoder_mse         0.3018
ber_loss            0.3018
----------------------------------------
Epoch 6 training duration 9.93 sec
----------------------------------------
Running validation for epoch 6/300
total_loss          0.5626
encoder_mse         0.0011
decoder_mse         0.3745
ber_loss            0.3745
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-6.pyt
Saving checkpoint done.

Starting epoch 7/300
Batch size = 32
Steps in epoch = 15
Epoch: 7/300 Step: 10/15
total_loss          0.4522
encoder_mse         0.0010
decoder_mse         0.3010
ber_loss            0.3010
----------------------------------------
Epoch: 7/300 Step: 15/15
total_loss          0.4493
encoder_mse         0.0009
decoder_mse         0.2991
ber_loss            0.2991
----------------------------------------
Epoch 7 training duration 10.07 sec
----------------------------------------
Running validation for epoch 7/300
total_loss          0.5624
encoder_mse         0.0011
decoder_mse         0.3744
ber_loss            0.3744
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-7.pyt
Saving checkpoint done.

Starting epoch 8/300
Batch size = 32
Steps in epoch = 15
Epoch: 8/300 Step: 10/15
total_loss          0.4513
encoder_mse         0.0009
decoder_mse         0.3004
ber_loss            0.3004
----------------------------------------
Epoch: 8/300 Step: 15/15
total_loss          0.4515
encoder_mse         0.0009
decoder_mse         0.3006
ber_loss            0.3006
----------------------------------------
Epoch 8 training duration 9.99 sec
----------------------------------------
Running validation for epoch 8/300
total_loss          0.7507
encoder_mse         0.0011
decoder_mse         0.4999
ber_loss            0.4999
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-8.pyt
Saving checkpoint done.

Starting epoch 9/300
Batch size = 32
Steps in epoch = 15
Epoch: 9/300 Step: 10/15
total_loss          0.7510
encoder_mse         0.0010
decoder_mse         0.5002
ber_loss            0.5002
----------------------------------------
Epoch: 9/300 Step: 15/15
total_loss          0.7023
encoder_mse         0.0010
decoder_mse         0.4678
ber_loss            0.4678
----------------------------------------
Epoch 9 training duration 9.80 sec
----------------------------------------
Running validation for epoch 9/300
total_loss          0.6517
encoder_mse         0.0011
decoder_mse         0.4340
ber_loss            0.4340
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-9.pyt
Saving checkpoint done.

Starting epoch 10/300
Batch size = 32
Steps in epoch = 15
Epoch: 10/300 Step: 10/15
total_loss          0.6739
encoder_mse         0.0009
decoder_mse         0.4488
ber_loss            0.4488
----------------------------------------
Epoch: 10/300 Step: 15/15
total_loss          0.6504
encoder_mse         0.0010
decoder_mse         0.4332
ber_loss            0.4332
----------------------------------------
Epoch 10 training duration 10.22 sec
----------------------------------------
Running validation for epoch 10/300
total_loss          0.4645
encoder_mse         0.0011
decoder_mse         0.3091
ber_loss            0.3091
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-10.pyt
Saving checkpoint done.

Starting epoch 11/300
Batch size = 32
Steps in epoch = 15
Epoch: 11/300 Step: 10/15
total_loss          0.6725
encoder_mse         0.0009
decoder_mse         0.4479
ber_loss            0.4479
----------------------------------------
Epoch: 11/300 Step: 15/15
total_loss          0.6479
encoder_mse         0.0009
decoder_mse         0.4315
ber_loss            0.4315
----------------------------------------
Epoch 11 training duration 10.05 sec
----------------------------------------
Running validation for epoch 11/300
total_loss          0.5631
encoder_mse         0.0011
decoder_mse         0.3749
ber_loss            0.3749
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-11.pyt
Saving checkpoint done.

Starting epoch 12/300
Batch size = 32
Steps in epoch = 15
Epoch: 12/300 Step: 10/15
total_loss          0.6045
encoder_mse         0.0010
decoder_mse         0.4026
ber_loss            0.4026
----------------------------------------
Epoch: 12/300 Step: 15/15
total_loss          0.6041
encoder_mse         0.0009
decoder_mse         0.4023
ber_loss            0.4023
----------------------------------------
Epoch 12 training duration 10.41 sec
----------------------------------------
Running validation for epoch 12/300
total_loss          0.4734
encoder_mse         0.0011
decoder_mse         0.3151
ber_loss            0.3151
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-12.pyt
Saving checkpoint done.

Starting epoch 13/300
Batch size = 32
Steps in epoch = 15
Epoch: 13/300 Step: 10/15
total_loss          0.6692
encoder_mse         0.0009
decoder_mse         0.4457
ber_loss            0.4457
----------------------------------------
Epoch: 13/300 Step: 15/15
total_loss          0.6976
encoder_mse         0.0009
decoder_mse         0.4647
ber_loss            0.4647
----------------------------------------
Epoch 13 training duration 10.29 sec
----------------------------------------
Running validation for epoch 13/300
total_loss          0.4751
encoder_mse         0.0011
decoder_mse         0.3162
ber_loss            0.3162
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-13.pyt
Saving checkpoint done.

Starting epoch 14/300
Batch size = 32
Steps in epoch = 15
Epoch: 14/300 Step: 10/15
total_loss          0.7419
encoder_mse         0.0009
decoder_mse         0.4942
ber_loss            0.4942
----------------------------------------
Epoch: 14/300 Step: 15/15
total_loss          0.6952
encoder_mse         0.0009
decoder_mse         0.4630
ber_loss            0.4630
----------------------------------------
Epoch 14 training duration 10.25 sec
----------------------------------------
Running validation for epoch 14/300
total_loss          0.4699
encoder_mse         0.0011
decoder_mse         0.3128
ber_loss            0.3128
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-14.pyt
Saving checkpoint done.

Starting epoch 15/300
Batch size = 32
Steps in epoch = 15
Epoch: 15/300 Step: 10/15
total_loss          0.7491
encoder_mse         0.0009
decoder_mse         0.4990
ber_loss            0.4990
----------------------------------------
Epoch: 15/300 Step: 15/15
total_loss          0.7008
encoder_mse         0.0009
decoder_mse         0.4668
ber_loss            0.4668
----------------------------------------
Epoch 15 training duration 9.96 sec
----------------------------------------
Running validation for epoch 15/300
total_loss          0.6583
encoder_mse         0.0011
decoder_mse         0.4384
ber_loss            0.4384
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-15.pyt
Saving checkpoint done.

Starting epoch 16/300
Batch size = 32
Steps in epoch = 15
Epoch: 16/300 Step: 10/15
total_loss          0.6747
encoder_mse         0.0009
decoder_mse         0.4494
ber_loss            0.4494
----------------------------------------
Epoch: 16/300 Step: 15/15
total_loss          0.6976
encoder_mse         0.0009
decoder_mse         0.4646
ber_loss            0.4646
----------------------------------------
Epoch 16 training duration 9.83 sec
----------------------------------------
Running validation for epoch 16/300
total_loss          0.7624
encoder_mse         0.0011
decoder_mse         0.5078
ber_loss            0.5078
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-16.pyt
Saving checkpoint done.

Starting epoch 17/300
Batch size = 32
Steps in epoch = 15
Epoch: 17/300 Step: 10/15
total_loss          0.6000
encoder_mse         0.0009
decoder_mse         0.3996
ber_loss            0.3996
----------------------------------------
Epoch: 17/300 Step: 15/15
total_loss          0.6480
encoder_mse         0.0009
decoder_mse         0.4316
ber_loss            0.4316
----------------------------------------
Epoch 17 training duration 10.11 sec
----------------------------------------
Running validation for epoch 17/300
total_loss          0.4720
encoder_mse         0.0011
decoder_mse         0.3142
ber_loss            0.3142
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-17.pyt
Saving checkpoint done.

Starting epoch 18/300
Batch size = 32
Steps in epoch = 15
Epoch: 18/300 Step: 10/15
total_loss          0.7568
encoder_mse         0.0009
decoder_mse         0.5041
ber_loss            0.5041
----------------------------------------
Epoch: 18/300 Step: 15/15
total_loss          0.7043
encoder_mse         0.0010
decoder_mse         0.4691
ber_loss            0.4691
----------------------------------------
Epoch 18 training duration 9.96 sec
----------------------------------------
Running validation for epoch 18/300
total_loss          0.4709
encoder_mse         0.0011
decoder_mse         0.3134
ber_loss            0.3134
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-18.pyt
Saving checkpoint done.

Starting epoch 19/300
Batch size = 32
Steps in epoch = 15
Epoch: 19/300 Step: 10/15
total_loss          0.4556
encoder_mse         0.0009
decoder_mse         0.3033
ber_loss            0.3033
----------------------------------------
Epoch: 19/300 Step: 15/15
total_loss          0.5023
encoder_mse         0.0010
decoder_mse         0.3344
ber_loss            0.3344
----------------------------------------
Epoch 19 training duration 10.25 sec
----------------------------------------
Running validation for epoch 19/300
total_loss          0.6594
encoder_mse         0.0011
decoder_mse         0.4391
ber_loss            0.4391
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-19.pyt
Saving checkpoint done.

Starting epoch 20/300
Batch size = 32
Steps in epoch = 15
Epoch: 20/300 Step: 10/15
total_loss          0.6011
encoder_mse         0.0009
decoder_mse         0.4003
ber_loss            0.4003
----------------------------------------
Epoch: 20/300 Step: 15/15
total_loss          0.6534
encoder_mse         0.0009
decoder_mse         0.4352
ber_loss            0.4352
----------------------------------------
Epoch 20 training duration 9.97 sec
----------------------------------------
Running validation for epoch 20/300
total_loss          0.6615
encoder_mse         0.0011
decoder_mse         0.4405
ber_loss            0.4405
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-20.pyt
Saving checkpoint done.

Starting epoch 21/300
Batch size = 32
Steps in epoch = 15
Epoch: 21/300 Step: 10/15
total_loss          0.7534
encoder_mse         0.0009
decoder_mse         0.5019
ber_loss            0.5019
----------------------------------------
Epoch: 21/300 Step: 15/15
total_loss          0.7545
encoder_mse         0.0009
decoder_mse         0.5025
ber_loss            0.5025
----------------------------------------
Epoch 21 training duration 9.93 sec
----------------------------------------
Running validation for epoch 21/300
total_loss          0.4705
encoder_mse         0.0011
decoder_mse         0.3132
ber_loss            0.3132
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-21.pyt
Saving checkpoint done.

Starting epoch 22/300
Batch size = 32
Steps in epoch = 15
Epoch: 22/300 Step: 10/15
total_loss          0.6810
encoder_mse         0.0009
decoder_mse         0.4536
ber_loss            0.4536
----------------------------------------
Epoch: 22/300 Step: 15/15
total_loss          0.6046
encoder_mse         0.0009
decoder_mse         0.4026
ber_loss            0.4026
----------------------------------------
Epoch 22 training duration 10.25 sec
----------------------------------------
Running validation for epoch 22/300
total_loss          0.7599
encoder_mse         0.0011
decoder_mse         0.5061
ber_loss            0.5061
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-22.pyt
Saving checkpoint done.

Starting epoch 23/300
Batch size = 32
Steps in epoch = 15
Epoch: 23/300 Step: 10/15
total_loss          0.3729
encoder_mse         0.0009
decoder_mse         0.2481
ber_loss            0.2481
----------------------------------------
Epoch: 23/300 Step: 15/15
total_loss          0.4012
encoder_mse         0.0009
decoder_mse         0.2670
ber_loss            0.2670
----------------------------------------
Epoch 23 training duration 9.79 sec
----------------------------------------
Running validation for epoch 23/300
total_loss          0.5620
encoder_mse         0.0011
decoder_mse         0.3741
ber_loss            0.3741
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-23.pyt
Saving checkpoint done.

Starting epoch 24/300
Batch size = 32
Steps in epoch = 15
Epoch: 24/300 Step: 10/15
total_loss          0.5291
encoder_mse         0.0009
decoder_mse         0.3523
ber_loss            0.3523
----------------------------------------
Epoch: 24/300 Step: 15/15
total_loss          0.6048
encoder_mse         0.0009
decoder_mse         0.4028
ber_loss            0.4028
----------------------------------------
Epoch 24 training duration 9.73 sec
----------------------------------------
Running validation for epoch 24/300
total_loss          0.6618
encoder_mse         0.0011
decoder_mse         0.4407
ber_loss            0.4407
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-24.pyt
Saving checkpoint done.

Starting epoch 25/300
Batch size = 32
Steps in epoch = 15
Epoch: 25/300 Step: 10/15
total_loss          0.5309
encoder_mse         0.0010
decoder_mse         0.3535
ber_loss            0.3535
----------------------------------------
Epoch: 25/300 Step: 15/15
total_loss          0.6044
encoder_mse         0.0009
decoder_mse         0.4025
ber_loss            0.4025
----------------------------------------
Epoch 25 training duration 10.07 sec
----------------------------------------
Running validation for epoch 25/300
total_loss          0.4708
encoder_mse         0.0011
decoder_mse         0.3134
ber_loss            0.3134
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-25.pyt
Saving checkpoint done.

Starting epoch 26/300
Batch size = 32
Steps in epoch = 15
Epoch: 26/300 Step: 10/15
total_loss          0.6087
encoder_mse         0.0010
decoder_mse         0.4053
ber_loss            0.4053
----------------------------------------
Epoch: 26/300 Step: 15/15
total_loss          0.6565
encoder_mse         0.0010
decoder_mse         0.4372
ber_loss            0.4372
----------------------------------------
Epoch 26 training duration 9.88 sec
----------------------------------------
Running validation for epoch 26/300
total_loss          0.4715
encoder_mse         0.0011
decoder_mse         0.3138
ber_loss            0.3138
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-26.pyt
Saving checkpoint done.

Starting epoch 27/300
Batch size = 32
Steps in epoch = 15
Epoch: 27/300 Step: 10/15
total_loss          0.6838
encoder_mse         0.0009
decoder_mse         0.4555
ber_loss            0.4555
----------------------------------------
Epoch: 27/300 Step: 15/15
total_loss          0.6595
encoder_mse         0.0009
decoder_mse         0.4393
ber_loss            0.4393
----------------------------------------
Epoch 27 training duration 10.13 sec
----------------------------------------
Running validation for epoch 27/300
total_loss          0.5622
encoder_mse         0.0011
decoder_mse         0.3743
ber_loss            0.3743
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-27.pyt
Saving checkpoint done.

Starting epoch 28/300
Batch size = 32
Steps in epoch = 15
Epoch: 28/300 Step: 10/15
total_loss          0.6002
encoder_mse         0.0009
decoder_mse         0.3997
ber_loss            0.3997
----------------------------------------
Epoch: 28/300 Step: 15/15
total_loss          0.5521
encoder_mse         0.0009
decoder_mse         0.3676
ber_loss            0.3676
----------------------------------------
Epoch 28 training duration 9.95 sec
----------------------------------------
Running validation for epoch 28/300
total_loss          0.6591
encoder_mse         0.0011
decoder_mse         0.4389
ber_loss            0.4389
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-28.pyt
Saving checkpoint done.

Starting epoch 29/300
Batch size = 32
Steps in epoch = 15
Epoch: 29/300 Step: 10/15
total_loss          0.6022
encoder_mse         0.0009
decoder_mse         0.4010
ber_loss            0.4010
----------------------------------------
Epoch: 29/300 Step: 15/15
total_loss          0.6513
encoder_mse         0.0009
decoder_mse         0.4338
ber_loss            0.4338
----------------------------------------
Epoch 29 training duration 10.31 sec
----------------------------------------
Running validation for epoch 29/300
total_loss          0.7501
encoder_mse         0.0011
decoder_mse         0.4996
ber_loss            0.4996
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-29.pyt
Saving checkpoint done.

Starting epoch 30/300
Batch size = 32
Steps in epoch = 15
Epoch: 30/300 Step: 10/15
total_loss          0.5279
encoder_mse         0.0009
decoder_mse         0.3515
ber_loss            0.3515
----------------------------------------
Epoch: 30/300 Step: 15/15
total_loss          0.5037
encoder_mse         0.0009
decoder_mse         0.3354
ber_loss            0.3354
----------------------------------------
Epoch 30 training duration 9.61 sec
----------------------------------------
Running validation for epoch 30/300
total_loss          0.7527
encoder_mse         0.0011
decoder_mse         0.5013
ber_loss            0.5013
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-30.pyt
Saving checkpoint done.

Starting epoch 31/300
Batch size = 32
Steps in epoch = 15
Epoch: 31/300 Step: 10/15
total_loss          0.2995
encoder_mse         0.0010
decoder_mse         0.1992
ber_loss            0.1992
----------------------------------------
Epoch: 31/300 Step: 15/15
total_loss          0.3991
encoder_mse         0.0010
decoder_mse         0.2656
ber_loss            0.2656
----------------------------------------
Epoch 31 training duration 10.11 sec
----------------------------------------
Running validation for epoch 31/300
total_loss          0.5646
encoder_mse         0.0011
decoder_mse         0.3759
ber_loss            0.3759
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-31.pyt
Saving checkpoint done.

Starting epoch 32/300
Batch size = 32
Steps in epoch = 15
Epoch: 32/300 Step: 10/15
total_loss          0.5276
encoder_mse         0.0010
decoder_mse         0.3513
ber_loss            0.3513
----------------------------------------
Epoch: 32/300 Step: 15/15
total_loss          0.5539
encoder_mse         0.0010
decoder_mse         0.3688
ber_loss            0.3688
----------------------------------------
Epoch 32 training duration 10.23 sec
----------------------------------------
Running validation for epoch 32/300
total_loss          0.6561
encoder_mse         0.0011
decoder_mse         0.4369
ber_loss            0.4369
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-32.pyt
Saving checkpoint done.

Starting epoch 33/300
Batch size = 32
Steps in epoch = 15
Epoch: 33/300 Step: 10/15
total_loss          0.6051
encoder_mse         0.0009
decoder_mse         0.4030
ber_loss            0.4030
----------------------------------------
Epoch: 33/300 Step: 15/15
total_loss          0.6539
encoder_mse         0.0009
decoder_mse         0.4355
ber_loss            0.4355
----------------------------------------
Epoch 33 training duration 10.26 sec
----------------------------------------
Running validation for epoch 33/300
total_loss          0.4695
encoder_mse         0.0011
decoder_mse         0.3125
ber_loss            0.3125
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-33.pyt
Saving checkpoint done.

Starting epoch 34/300
Batch size = 32
Steps in epoch = 15
Epoch: 34/300 Step: 10/15
total_loss          0.6794
encoder_mse         0.0009
decoder_mse         0.4525
ber_loss            0.4525
----------------------------------------
Epoch: 34/300 Step: 15/15
total_loss          0.6547
encoder_mse         0.0009
decoder_mse         0.4361
ber_loss            0.4361
----------------------------------------
Epoch 34 training duration 9.90 sec
----------------------------------------
Running validation for epoch 34/300
total_loss          0.6569
encoder_mse         0.0011
decoder_mse         0.4374
ber_loss            0.4374
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-34.pyt
Saving checkpoint done.

Starting epoch 35/300
Batch size = 32
Steps in epoch = 15
Epoch: 35/300 Step: 10/15
total_loss          0.6011
encoder_mse         0.0009
decoder_mse         0.4003
ber_loss            0.4003
----------------------------------------
Epoch: 35/300 Step: 15/15
total_loss          0.5023
encoder_mse         0.0009
decoder_mse         0.3344
ber_loss            0.3344
----------------------------------------
Epoch 35 training duration 9.95 sec
----------------------------------------
Running validation for epoch 35/300
total_loss          0.3734
encoder_mse         0.0011
decoder_mse         0.2484
ber_loss            0.2484
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-35.pyt
Saving checkpoint done.

Starting epoch 36/300
Batch size = 32
Steps in epoch = 15
Epoch: 36/300 Step: 10/15
total_loss          0.5301
encoder_mse         0.0009
decoder_mse         0.3530
ber_loss            0.3530
----------------------------------------
Epoch: 36/300 Step: 15/15
total_loss          0.5526
encoder_mse         0.0009
decoder_mse         0.3680
ber_loss            0.3680
----------------------------------------
Epoch 36 training duration 10.20 sec
----------------------------------------
Running validation for epoch 36/300
total_loss          0.5633
encoder_mse         0.0011
decoder_mse         0.3750
ber_loss            0.3750
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-36.pyt
Saving checkpoint done.

Starting epoch 37/300
Batch size = 32
Steps in epoch = 15
Epoch: 37/300 Step: 10/15
total_loss          0.4527
encoder_mse         0.0010
decoder_mse         0.3013
ber_loss            0.3013
----------------------------------------
Epoch: 37/300 Step: 15/15
total_loss          0.5024
encoder_mse         0.0010
decoder_mse         0.3345
ber_loss            0.3345
----------------------------------------
Epoch 37 training duration 10.18 sec
----------------------------------------
Running validation for epoch 37/300
total_loss          0.4738
encoder_mse         0.0011
decoder_mse         0.3154
ber_loss            0.3154
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-37.pyt
Saving checkpoint done.

Starting epoch 38/300
Batch size = 32
Steps in epoch = 15
Epoch: 38/300 Step: 10/15
total_loss          0.6785
encoder_mse         0.0009
decoder_mse         0.4519
ber_loss            0.4519
----------------------------------------
Epoch: 38/300 Step: 15/15
total_loss          0.6003
encoder_mse         0.0009
decoder_mse         0.3998
ber_loss            0.3998
----------------------------------------
Epoch 38 training duration 9.91 sec
----------------------------------------
Running validation for epoch 38/300
total_loss          0.5644
encoder_mse         0.0011
decoder_mse         0.3757
ber_loss            0.3757
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-38.pyt
Saving checkpoint done.

Starting epoch 39/300
Batch size = 32
Steps in epoch = 15
Epoch: 39/300 Step: 10/15
total_loss          0.6815
encoder_mse         0.0010
decoder_mse         0.4539
ber_loss            0.4539
----------------------------------------
Epoch: 39/300 Step: 15/15
total_loss          0.6053
encoder_mse         0.0010
decoder_mse         0.4031
ber_loss            0.4031
----------------------------------------
Epoch 39 training duration 10.46 sec
----------------------------------------
Running validation for epoch 39/300
total_loss          0.5644
encoder_mse         0.0011
decoder_mse         0.3757
ber_loss            0.3757
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-39.pyt
Saving checkpoint done.

Starting epoch 40/300
Batch size = 32
Steps in epoch = 15
Epoch: 40/300 Step: 10/15
total_loss          0.6758
encoder_mse         0.0009
decoder_mse         0.4501
ber_loss            0.4501
----------------------------------------
Epoch: 40/300 Step: 15/15
total_loss          0.7004
encoder_mse         0.0009
decoder_mse         0.4665
ber_loss            0.4665
----------------------------------------
Epoch 40 training duration 10.13 sec
----------------------------------------
Running validation for epoch 40/300
total_loss          0.4697
encoder_mse         0.0011
decoder_mse         0.3126
ber_loss            0.3126
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-40.pyt
Saving checkpoint done.

Starting epoch 41/300
Batch size = 32
Steps in epoch = 15
Epoch: 41/300 Step: 10/15
total_loss          0.6088
encoder_mse         0.0009
decoder_mse         0.4054
ber_loss            0.4054
----------------------------------------
Epoch: 41/300 Step: 15/15
total_loss          0.6071
encoder_mse         0.0009
decoder_mse         0.4043
ber_loss            0.4043
----------------------------------------
Epoch 41 training duration 10.27 sec
----------------------------------------
Running validation for epoch 41/300
total_loss          0.6598
encoder_mse         0.0011
decoder_mse         0.4393
ber_loss            0.4393
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-41.pyt
Saving checkpoint done.

Starting epoch 42/300
Batch size = 32
Steps in epoch = 15
Epoch: 42/300 Step: 10/15
total_loss          0.5283
encoder_mse         0.0009
decoder_mse         0.3518
ber_loss            0.3518
----------------------------------------
Epoch: 42/300 Step: 15/15
total_loss          0.5531
encoder_mse         0.0009
decoder_mse         0.3683
ber_loss            0.3683
----------------------------------------
Epoch 42 training duration 10.04 sec
----------------------------------------
Running validation for epoch 42/300
total_loss          0.4646
encoder_mse         0.0011
decoder_mse         0.3092
ber_loss            0.3092
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-42.pyt
Saving checkpoint done.

Starting epoch 43/300
Batch size = 32
Steps in epoch = 15
Epoch: 43/300 Step: 10/15
total_loss          0.6012
encoder_mse         0.0009
decoder_mse         0.4004
ber_loss            0.4004
----------------------------------------
Epoch: 43/300 Step: 15/15
total_loss          0.5997
encoder_mse         0.0009
decoder_mse         0.3994
ber_loss            0.3994
----------------------------------------
Epoch 43 training duration 9.76 sec
----------------------------------------
Running validation for epoch 43/300
total_loss          0.5652
encoder_mse         0.0011
decoder_mse         0.3763
ber_loss            0.3763
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-43.pyt
Saving checkpoint done.

Starting epoch 44/300
Batch size = 32
Steps in epoch = 15
Epoch: 44/300 Step: 10/15
total_loss          0.5278
encoder_mse         0.0010
decoder_mse         0.3514
ber_loss            0.3514
----------------------------------------
Epoch: 44/300 Step: 15/15
total_loss          0.5503
encoder_mse         0.0009
decoder_mse         0.3664
ber_loss            0.3664
----------------------------------------
Epoch 44 training duration 10.02 sec
----------------------------------------
Running validation for epoch 44/300
total_loss          0.6586
encoder_mse         0.0011
decoder_mse         0.4386
ber_loss            0.4386
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-44.pyt
Saving checkpoint done.

Starting epoch 45/300
Batch size = 32
Steps in epoch = 15
Epoch: 45/300 Step: 10/15
total_loss          0.5979
encoder_mse         0.0010
decoder_mse         0.3981
ber_loss            0.3981
----------------------------------------
Epoch: 45/300 Step: 15/15
total_loss          0.6004
encoder_mse         0.0009
decoder_mse         0.3999
ber_loss            0.3999
----------------------------------------
Epoch 45 training duration 10.09 sec
----------------------------------------
Running validation for epoch 45/300
total_loss          0.6541
encoder_mse         0.0011
decoder_mse         0.4355
ber_loss            0.4355
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-45.pyt
Saving checkpoint done.

Starting epoch 46/300
Batch size = 32
Steps in epoch = 15
Epoch: 46/300 Step: 10/15
total_loss          0.6823
encoder_mse         0.0009
decoder_mse         0.4544
ber_loss            0.4544
----------------------------------------
Epoch: 46/300 Step: 15/15
total_loss          0.7036
encoder_mse         0.0009
decoder_mse         0.4686
ber_loss            0.4686
----------------------------------------
Epoch 46 training duration 10.16 sec
----------------------------------------
Running validation for epoch 46/300
total_loss          0.6565
encoder_mse         0.0011
decoder_mse         0.4371
ber_loss            0.4371
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-46.pyt
Saving checkpoint done.

Starting epoch 47/300
Batch size = 32
Steps in epoch = 15
Epoch: 47/300 Step: 10/15
total_loss          0.6006
encoder_mse         0.0009
decoder_mse         0.4000
ber_loss            0.4000
----------------------------------------
Epoch: 47/300 Step: 15/15
total_loss          0.6025
encoder_mse         0.0009
decoder_mse         0.4012
ber_loss            0.4012
----------------------------------------
Epoch 47 training duration 9.91 sec
----------------------------------------
Running validation for epoch 47/300
total_loss          0.4719
encoder_mse         0.0011
decoder_mse         0.3141
ber_loss            0.3141
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-47.pyt
Saving checkpoint done.

Starting epoch 48/300
Batch size = 32
Steps in epoch = 15
Epoch: 48/300 Step: 10/15
total_loss          0.6805
encoder_mse         0.0009
decoder_mse         0.4532
ber_loss            0.4532
----------------------------------------
Epoch: 48/300 Step: 15/15
total_loss          0.6513
encoder_mse         0.0010
decoder_mse         0.4338
ber_loss            0.4338
----------------------------------------
Epoch 48 training duration 10.19 sec
----------------------------------------
Running validation for epoch 48/300
total_loss          0.4662
encoder_mse         0.0011
decoder_mse         0.3103
ber_loss            0.3103
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-48.pyt
Saving checkpoint done.

Starting epoch 49/300
Batch size = 32
Steps in epoch = 15
Epoch: 49/300 Step: 10/15
total_loss          0.6756
encoder_mse         0.0009
decoder_mse         0.4500
ber_loss            0.4500
----------------------------------------
Epoch: 49/300 Step: 15/15
total_loss          0.6514
encoder_mse         0.0010
decoder_mse         0.4338
ber_loss            0.4338
----------------------------------------
Epoch 49 training duration 10.26 sec
----------------------------------------
Running validation for epoch 49/300
total_loss          0.4611
encoder_mse         0.0011
decoder_mse         0.3069
ber_loss            0.3069
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-49.pyt
Saving checkpoint done.

Starting epoch 50/300
Batch size = 32
Steps in epoch = 15
Epoch: 50/300 Step: 10/15
total_loss          0.6051
encoder_mse         0.0009
decoder_mse         0.4030
ber_loss            0.4030
----------------------------------------
Epoch: 50/300 Step: 15/15
total_loss          0.5539
encoder_mse         0.0009
decoder_mse         0.3688
ber_loss            0.3688
----------------------------------------
Epoch 50 training duration 10.43 sec
----------------------------------------
Running validation for epoch 50/300
total_loss          0.5615
encoder_mse         0.0011
decoder_mse         0.3738
ber_loss            0.3738
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-50.pyt
Saving checkpoint done.

Starting epoch 51/300
Batch size = 32
Steps in epoch = 15
Epoch: 51/300 Step: 10/15
total_loss          0.6796
encoder_mse         0.0010
decoder_mse         0.4526
ber_loss            0.4526
----------------------------------------
Epoch: 51/300 Step: 15/15
total_loss          0.6542
encoder_mse         0.0010
decoder_mse         0.4357
ber_loss            0.4357
----------------------------------------
Epoch 51 training duration 10.08 sec
----------------------------------------
Running validation for epoch 51/300
total_loss          0.6565
encoder_mse         0.0011
decoder_mse         0.4371
ber_loss            0.4371
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-51.pyt
Saving checkpoint done.

Starting epoch 52/300
Batch size = 32
Steps in epoch = 15
Epoch: 52/300 Step: 10/15
total_loss          0.5307
encoder_mse         0.0009
decoder_mse         0.3534
ber_loss            0.3534
----------------------------------------
Epoch: 52/300 Step: 15/15
total_loss          0.6023
encoder_mse         0.0009
decoder_mse         0.4011
ber_loss            0.4011
----------------------------------------
Epoch 52 training duration 9.47 sec
----------------------------------------
Running validation for epoch 52/300
total_loss          0.5686
encoder_mse         0.0011
decoder_mse         0.3785
ber_loss            0.3785
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-52.pyt
Saving checkpoint done.

Starting epoch 53/300
Batch size = 32
Steps in epoch = 15
Epoch: 53/300 Step: 10/15
total_loss          0.6742
encoder_mse         0.0010
decoder_mse         0.4490
ber_loss            0.4490
----------------------------------------
Epoch: 53/300 Step: 15/15
total_loss          0.6004
encoder_mse         0.0009
decoder_mse         0.3999
ber_loss            0.3999
----------------------------------------
Epoch 53 training duration 10.64 sec
----------------------------------------
Running validation for epoch 53/300
total_loss          0.6619
encoder_mse         0.0011
decoder_mse         0.4407
ber_loss            0.4407
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-53.pyt
Saving checkpoint done.

Starting epoch 54/300
Batch size = 32
Steps in epoch = 15
Epoch: 54/300 Step: 10/15
total_loss          0.6808
encoder_mse         0.0010
decoder_mse         0.4534
ber_loss            0.4534
----------------------------------------
Epoch: 54/300 Step: 15/15
total_loss          0.6546
encoder_mse         0.0009
decoder_mse         0.4360
ber_loss            0.4360
----------------------------------------
Epoch 54 training duration 10.03 sec
----------------------------------------
Running validation for epoch 54/300
total_loss          0.6594
encoder_mse         0.0011
decoder_mse         0.4391
ber_loss            0.4391
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-54.pyt
Saving checkpoint done.

Starting epoch 55/300
Batch size = 32
Steps in epoch = 15
Epoch: 55/300 Step: 10/15
total_loss          0.6769
encoder_mse         0.0009
decoder_mse         0.4508
ber_loss            0.4508
----------------------------------------
Epoch: 55/300 Step: 15/15
total_loss          0.6024
encoder_mse         0.0009
decoder_mse         0.4012
ber_loss            0.4012
----------------------------------------
Epoch 55 training duration 10.04 sec
----------------------------------------
Running validation for epoch 55/300
total_loss          0.3799
encoder_mse         0.0011
decoder_mse         0.2527
ber_loss            0.2527
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-55.pyt
Saving checkpoint done.

Starting epoch 56/300
Batch size = 32
Steps in epoch = 15
Epoch: 56/300 Step: 10/15
total_loss          0.7525
encoder_mse         0.0009
decoder_mse         0.5012
ber_loss            0.5012
----------------------------------------
Epoch: 56/300 Step: 15/15
total_loss          0.7560
encoder_mse         0.0009
decoder_mse         0.5036
ber_loss            0.5036
----------------------------------------
Epoch 56 training duration 10.11 sec
----------------------------------------
Running validation for epoch 56/300
total_loss          0.6616
encoder_mse         0.0011
decoder_mse         0.4406
ber_loss            0.4406
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-56.pyt
Saving checkpoint done.

Starting epoch 57/300
Batch size = 32
Steps in epoch = 15
Epoch: 57/300 Step: 10/15
total_loss          0.6092
encoder_mse         0.0009
decoder_mse         0.4057
ber_loss            0.4057
----------------------------------------
Epoch: 57/300 Step: 15/15
total_loss          0.6533
encoder_mse         0.0009
decoder_mse         0.4351
ber_loss            0.4351
----------------------------------------
Epoch 57 training duration 9.78 sec
----------------------------------------
Running validation for epoch 57/300
total_loss          0.6528
encoder_mse         0.0011
decoder_mse         0.4347
ber_loss            0.4347
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-57.pyt
Saving checkpoint done.

Starting epoch 58/300
Batch size = 32
Steps in epoch = 15
Epoch: 58/300 Step: 10/15
total_loss          0.6026
encoder_mse         0.0009
decoder_mse         0.4013
ber_loss            0.4013
----------------------------------------
Epoch: 58/300 Step: 15/15
total_loss          0.5021
encoder_mse         0.0009
decoder_mse         0.3343
ber_loss            0.3343
----------------------------------------
Epoch 58 training duration 10.26 sec
----------------------------------------
Running validation for epoch 58/300
total_loss          0.4685
encoder_mse         0.0011
decoder_mse         0.3118
ber_loss            0.3118
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-58.pyt
Saving checkpoint done.

Starting epoch 59/300
Batch size = 32
Steps in epoch = 15
Epoch: 59/300 Step: 10/15
total_loss          0.5222
encoder_mse         0.0009
decoder_mse         0.3477
ber_loss            0.3477
----------------------------------------
Epoch: 59/300 Step: 15/15
total_loss          0.4996
encoder_mse         0.0010
decoder_mse         0.3326
ber_loss            0.3326
----------------------------------------
Epoch 59 training duration 10.17 sec
----------------------------------------
Running validation for epoch 59/300
total_loss          0.3786
encoder_mse         0.0011
decoder_mse         0.2519
ber_loss            0.2519
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-59.pyt
Saving checkpoint done.

Starting epoch 60/300
Batch size = 32
Steps in epoch = 15
Epoch: 60/300 Step: 10/15
total_loss          0.4491
encoder_mse         0.0009
decoder_mse         0.2990
ber_loss            0.2990
----------------------------------------
Epoch: 60/300 Step: 15/15
total_loss          0.4996
encoder_mse         0.0009
decoder_mse         0.3326
ber_loss            0.3326
----------------------------------------
Epoch 60 training duration 9.54 sec
----------------------------------------
Running validation for epoch 60/300
total_loss          0.4682
encoder_mse         0.0011
decoder_mse         0.3116
ber_loss            0.3116
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-60.pyt
Saving checkpoint done.

Starting epoch 61/300
Batch size = 32
Steps in epoch = 15
Epoch: 61/300 Step: 10/15
total_loss          0.5977
encoder_mse         0.0009
decoder_mse         0.3981
ber_loss            0.3981
----------------------------------------
Epoch: 61/300 Step: 15/15
total_loss          0.4989
encoder_mse         0.0009
decoder_mse         0.3322
ber_loss            0.3322
----------------------------------------
Epoch 61 training duration 9.78 sec
----------------------------------------
Running validation for epoch 61/300
total_loss          0.5665
encoder_mse         0.0011
decoder_mse         0.3772
ber_loss            0.3772
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-61.pyt
Saving checkpoint done.

Starting epoch 62/300
Batch size = 32
Steps in epoch = 15
Epoch: 62/300 Step: 10/15
total_loss          0.3747
encoder_mse         0.0010
decoder_mse         0.2493
ber_loss            0.2493
----------------------------------------
Epoch: 62/300 Step: 15/15
total_loss          0.5005
encoder_mse         0.0010
decoder_mse         0.3332
ber_loss            0.3332
----------------------------------------
Epoch 62 training duration 10.32 sec
----------------------------------------
Running validation for epoch 62/300
total_loss          0.7539
encoder_mse         0.0011
decoder_mse         0.5021
ber_loss            0.5021
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-62.pyt
Saving checkpoint done.

Starting epoch 63/300
Batch size = 32
Steps in epoch = 15
Epoch: 63/300 Step: 10/15
total_loss          0.6755
encoder_mse         0.0009
decoder_mse         0.4499
ber_loss            0.4499
----------------------------------------
Epoch: 63/300 Step: 15/15
total_loss          0.6009
encoder_mse         0.0009
decoder_mse         0.4002
ber_loss            0.4002
----------------------------------------
Epoch 63 training duration 10.00 sec
----------------------------------------
Running validation for epoch 63/300
total_loss          0.6611
encoder_mse         0.0011
decoder_mse         0.4402
ber_loss            0.4402
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-63.pyt
Saving checkpoint done.

Starting epoch 64/300
Batch size = 32
Steps in epoch = 15
Epoch: 64/300 Step: 10/15
total_loss          0.7570
encoder_mse         0.0009
decoder_mse         0.5042
ber_loss            0.5042
----------------------------------------
Epoch: 64/300 Step: 15/15
total_loss          0.7040
encoder_mse         0.0009
decoder_mse         0.4689
ber_loss            0.4689
----------------------------------------
Epoch 64 training duration 10.01 sec
----------------------------------------
Running validation for epoch 64/300
total_loss          0.2842
encoder_mse         0.0011
decoder_mse         0.1889
ber_loss            0.1889
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-64.pyt
Saving checkpoint done.

Starting epoch 65/300
Batch size = 32
Steps in epoch = 15
Epoch: 65/300 Step: 10/15
total_loss          0.5253
encoder_mse         0.0009
decoder_mse         0.3498
ber_loss            0.3498
----------------------------------------
Epoch: 65/300 Step: 15/15
total_loss          0.5532
encoder_mse         0.0009
decoder_mse         0.3684
ber_loss            0.3684
----------------------------------------
Epoch 65 training duration 10.19 sec
----------------------------------------
Running validation for epoch 65/300
total_loss          0.6592
encoder_mse         0.0011
decoder_mse         0.4389
ber_loss            0.4389
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-65.pyt
Saving checkpoint done.

Starting epoch 66/300
Batch size = 32
Steps in epoch = 15
Epoch: 66/300 Step: 10/15
total_loss          0.7555
encoder_mse         0.0010
decoder_mse         0.5032
ber_loss            0.5032
----------------------------------------
Epoch: 66/300 Step: 15/15
total_loss          0.6540
encoder_mse         0.0009
decoder_mse         0.4356
ber_loss            0.4356
----------------------------------------
Epoch 66 training duration 10.15 sec
----------------------------------------
Running validation for epoch 66/300
total_loss          0.7471
encoder_mse         0.0011
decoder_mse         0.4975
ber_loss            0.4975
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-66.pyt
Saving checkpoint done.

Starting epoch 67/300
Batch size = 32
Steps in epoch = 15
Epoch: 67/300 Step: 10/15
total_loss          0.6043
encoder_mse         0.0010
decoder_mse         0.4024
ber_loss            0.4024
----------------------------------------
Epoch: 67/300 Step: 15/15
total_loss          0.6559
encoder_mse         0.0010
decoder_mse         0.4368
ber_loss            0.4368
----------------------------------------
Epoch 67 training duration 10.25 sec
----------------------------------------
Running validation for epoch 67/300
total_loss          0.7516
encoder_mse         0.0011
decoder_mse         0.5006
ber_loss            0.5006
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-67.pyt
Saving checkpoint done.

Starting epoch 68/300
Batch size = 32
Steps in epoch = 15
Epoch: 68/300 Step: 10/15
total_loss          0.6027
encoder_mse         0.0009
decoder_mse         0.4014
ber_loss            0.4014
----------------------------------------
Epoch: 68/300 Step: 15/15
total_loss          0.6523
encoder_mse         0.0010
decoder_mse         0.4344
ber_loss            0.4344
----------------------------------------
Epoch 68 training duration 10.30 sec
----------------------------------------
Running validation for epoch 68/300
total_loss          0.3740
encoder_mse         0.0011
decoder_mse         0.2489
ber_loss            0.2489
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-68.pyt
Saving checkpoint done.

Starting epoch 69/300
Batch size = 32
Steps in epoch = 15
Epoch: 69/300 Step: 10/15
total_loss          0.6737
encoder_mse         0.0010
decoder_mse         0.4487
ber_loss            0.4487
----------------------------------------
Epoch: 69/300 Step: 15/15
total_loss          0.7008
encoder_mse         0.0010
decoder_mse         0.4668
ber_loss            0.4668
----------------------------------------
Epoch 69 training duration 10.38 sec
----------------------------------------
Running validation for epoch 69/300
total_loss          0.7575
encoder_mse         0.0011
decoder_mse         0.5045
ber_loss            0.5045
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-69.pyt
Saving checkpoint done.

Starting epoch 70/300
Batch size = 32
Steps in epoch = 15
Epoch: 70/300 Step: 10/15
total_loss          0.5255
encoder_mse         0.0010
decoder_mse         0.3499
ber_loss            0.3499
----------------------------------------
Epoch: 70/300 Step: 15/15
total_loss          0.4526
encoder_mse         0.0009
decoder_mse         0.3013
ber_loss            0.3013
----------------------------------------
Epoch 70 training duration 10.03 sec
----------------------------------------
Running validation for epoch 70/300
total_loss          0.6627
encoder_mse         0.0011
decoder_mse         0.4413
ber_loss            0.4413
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-70.pyt
Saving checkpoint done.

Starting epoch 71/300
Batch size = 32
Steps in epoch = 15
Epoch: 71/300 Step: 10/15
total_loss          0.5277
encoder_mse         0.0010
decoder_mse         0.3514
ber_loss            0.3514
----------------------------------------
Epoch: 71/300 Step: 15/15
total_loss          0.5538
encoder_mse         0.0010
decoder_mse         0.3688
ber_loss            0.3688
----------------------------------------
Epoch 71 training duration 10.30 sec
----------------------------------------
Running validation for epoch 71/300
total_loss          0.6509
encoder_mse         0.0011
decoder_mse         0.4334
ber_loss            0.4334
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-71.pyt
Saving checkpoint done.

Starting epoch 72/300
Batch size = 32
Steps in epoch = 15
Epoch: 72/300 Step: 10/15
total_loss          0.4462
encoder_mse         0.0009
decoder_mse         0.2970
ber_loss            0.2970
----------------------------------------
Epoch: 72/300 Step: 15/15
total_loss          0.4472
encoder_mse         0.0009
decoder_mse         0.2977
ber_loss            0.2977
----------------------------------------
Epoch 72 training duration 9.74 sec
----------------------------------------
Running validation for epoch 72/300
total_loss          0.7591
encoder_mse         0.0011
decoder_mse         0.5056
ber_loss            0.5056
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-72.pyt
Saving checkpoint done.

Starting epoch 73/300
Batch size = 32
Steps in epoch = 15
Epoch: 73/300 Step: 10/15
total_loss          0.6789
encoder_mse         0.0010
decoder_mse         0.4521
ber_loss            0.4521
----------------------------------------
Epoch: 73/300 Step: 15/15
total_loss          0.6051
encoder_mse         0.0010
decoder_mse         0.4030
ber_loss            0.4030
----------------------------------------
Epoch 73 training duration 10.04 sec
----------------------------------------
Running validation for epoch 73/300
total_loss          0.7536
encoder_mse         0.0011
decoder_mse         0.5019
ber_loss            0.5019
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-73.pyt
Saving checkpoint done.

Starting epoch 74/300
Batch size = 32
Steps in epoch = 15
Epoch: 74/300 Step: 10/15
total_loss          0.6038
encoder_mse         0.0009
decoder_mse         0.4021
ber_loss            0.4021
----------------------------------------
Epoch: 74/300 Step: 15/15
total_loss          0.6001
encoder_mse         0.0010
decoder_mse         0.3996
ber_loss            0.3996
----------------------------------------
Epoch 74 training duration 10.09 sec
----------------------------------------
Running validation for epoch 74/300
total_loss          0.4692
encoder_mse         0.0011
decoder_mse         0.3123
ber_loss            0.3123
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-74.pyt
Saving checkpoint done.

Starting epoch 75/300
Batch size = 32
Steps in epoch = 15
Epoch: 75/300 Step: 10/15
total_loss          0.5307
encoder_mse         0.0009
decoder_mse         0.3534
ber_loss            0.3534
----------------------------------------
Epoch: 75/300 Step: 15/15
total_loss          0.5543
encoder_mse         0.0009
decoder_mse         0.3691
ber_loss            0.3691
----------------------------------------
Epoch 75 training duration 10.10 sec
----------------------------------------
Running validation for epoch 75/300
total_loss          0.7522
encoder_mse         0.0011
decoder_mse         0.5009
ber_loss            0.5009
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-75.pyt
Saving checkpoint done.

Starting epoch 76/300
Batch size = 32
Steps in epoch = 15
Epoch: 76/300 Step: 10/15
total_loss          0.5301
encoder_mse         0.0009
decoder_mse         0.3530
ber_loss            0.3530
----------------------------------------
Epoch: 76/300 Step: 15/15
total_loss          0.4524
encoder_mse         0.0009
decoder_mse         0.3011
ber_loss            0.3011
----------------------------------------
Epoch 76 training duration 9.84 sec
----------------------------------------
Running validation for epoch 76/300
total_loss          0.6516
encoder_mse         0.0011
decoder_mse         0.4339
ber_loss            0.4339
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-76.pyt
Saving checkpoint done.

Starting epoch 77/300
Batch size = 32
Steps in epoch = 15
Epoch: 77/300 Step: 10/15
total_loss          0.7582
encoder_mse         0.0009
decoder_mse         0.5051
ber_loss            0.5051
----------------------------------------
Epoch: 77/300 Step: 15/15
total_loss          0.7051
encoder_mse         0.0009
decoder_mse         0.4697
ber_loss            0.4697
----------------------------------------
Epoch 77 training duration 10.63 sec
----------------------------------------
Running validation for epoch 77/300
total_loss          0.6543
encoder_mse         0.0011
decoder_mse         0.4357
ber_loss            0.4357
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-77.pyt
Saving checkpoint done.

Starting epoch 78/300
Batch size = 32
Steps in epoch = 15
Epoch: 78/300 Step: 10/15
total_loss          0.6828
encoder_mse         0.0010
decoder_mse         0.4547
ber_loss            0.4547
----------------------------------------
Epoch: 78/300 Step: 15/15
total_loss          0.6034
encoder_mse         0.0010
decoder_mse         0.4018
ber_loss            0.4018
----------------------------------------
Epoch 78 training duration 10.22 sec
----------------------------------------
Running validation for epoch 78/300
total_loss          0.6605
encoder_mse         0.0011
decoder_mse         0.4398
ber_loss            0.4398
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-78.pyt
Saving checkpoint done.

Starting epoch 79/300
Batch size = 32
Steps in epoch = 15
Epoch: 79/300 Step: 10/15
total_loss          0.5269
encoder_mse         0.0009
decoder_mse         0.3508
ber_loss            0.3508
----------------------------------------
Epoch: 79/300 Step: 15/15
total_loss          0.5515
encoder_mse         0.0009
decoder_mse         0.3673
ber_loss            0.3673
----------------------------------------
Epoch 79 training duration 9.96 sec
----------------------------------------
Running validation for epoch 79/300
total_loss          0.5603
encoder_mse         0.0011
decoder_mse         0.3730
ber_loss            0.3730
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-79.pyt
Saving checkpoint done.

Starting epoch 80/300
Batch size = 32
Steps in epoch = 15
Epoch: 80/300 Step: 10/15
total_loss          0.6041
encoder_mse         0.0009
decoder_mse         0.4023
ber_loss            0.4023
----------------------------------------
Epoch: 80/300 Step: 15/15
total_loss          0.6542
encoder_mse         0.0009
decoder_mse         0.4357
ber_loss            0.4357
----------------------------------------
Epoch 80 training duration 9.86 sec
----------------------------------------
Running validation for epoch 80/300
total_loss          0.4688
encoder_mse         0.0011
decoder_mse         0.3120
ber_loss            0.3120
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-80.pyt
Saving checkpoint done.

Starting epoch 81/300
Batch size = 32
Steps in epoch = 15
Epoch: 81/300 Step: 10/15
total_loss          0.4542
encoder_mse         0.0009
decoder_mse         0.3023
ber_loss            0.3023
----------------------------------------
Epoch: 81/300 Step: 15/15
total_loss          0.5041
encoder_mse         0.0010
decoder_mse         0.3356
ber_loss            0.3356
----------------------------------------
Epoch 81 training duration 10.27 sec
----------------------------------------
Running validation for epoch 81/300
total_loss          0.4702
encoder_mse         0.0011
decoder_mse         0.3130
ber_loss            0.3130
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-81.pyt
Saving checkpoint done.

Starting epoch 82/300
Batch size = 32
Steps in epoch = 15
Epoch: 82/300 Step: 10/15
total_loss          0.6708
encoder_mse         0.0010
decoder_mse         0.4467
ber_loss            0.4467
----------------------------------------
Epoch: 82/300 Step: 15/15
total_loss          0.5977
encoder_mse         0.0009
decoder_mse         0.3980
ber_loss            0.3980
----------------------------------------
Epoch 82 training duration 10.36 sec
----------------------------------------
Running validation for epoch 82/300
total_loss          0.5607
encoder_mse         0.0011
decoder_mse         0.3733
ber_loss            0.3733
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-82.pyt
Saving checkpoint done.

Starting epoch 83/300
Batch size = 32
Steps in epoch = 15
Epoch: 83/300 Step: 10/15
total_loss          0.4499
encoder_mse         0.0010
decoder_mse         0.2995
ber_loss            0.2995
----------------------------------------
Epoch: 83/300 Step: 15/15
total_loss          0.3995
encoder_mse         0.0009
decoder_mse         0.2659
ber_loss            0.2659
----------------------------------------
Epoch 83 training duration 9.80 sec
----------------------------------------
Running validation for epoch 83/300
total_loss          0.4676
encoder_mse         0.0011
decoder_mse         0.3112
ber_loss            0.3112
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-83.pyt
Saving checkpoint done.

Starting epoch 84/300
Batch size = 32
Steps in epoch = 15
Epoch: 84/300 Step: 10/15
total_loss          0.5948
encoder_mse         0.0010
decoder_mse         0.3961
ber_loss            0.3961
----------------------------------------
Epoch: 84/300 Step: 15/15
total_loss          0.5958
encoder_mse         0.0009
decoder_mse         0.3968
ber_loss            0.3968
----------------------------------------
Epoch 84 training duration 10.48 sec
----------------------------------------
Running validation for epoch 84/300
total_loss          0.7498
encoder_mse         0.0011
decoder_mse         0.4994
ber_loss            0.4994
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-84.pyt
Saving checkpoint done.

Starting epoch 85/300
Batch size = 32
Steps in epoch = 15
Epoch: 85/300 Step: 10/15
total_loss          0.6787
encoder_mse         0.0010
decoder_mse         0.4520
ber_loss            0.4520
----------------------------------------
Epoch: 85/300 Step: 15/15
total_loss          0.7040
encoder_mse         0.0009
decoder_mse         0.4689
ber_loss            0.4689
----------------------------------------
Epoch 85 training duration 10.39 sec
----------------------------------------
Running validation for epoch 85/300
total_loss          0.4678
encoder_mse         0.0011
decoder_mse         0.3113
ber_loss            0.3113
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-85.pyt
Saving checkpoint done.

Starting epoch 86/300
Batch size = 32
Steps in epoch = 15
Epoch: 86/300 Step: 10/15
total_loss          0.6046
encoder_mse         0.0010
decoder_mse         0.4026
ber_loss            0.4026
----------------------------------------
Epoch: 86/300 Step: 15/15
total_loss          0.6022
encoder_mse         0.0010
decoder_mse         0.4010
ber_loss            0.4010
----------------------------------------
Epoch 86 training duration 9.91 sec
----------------------------------------
Running validation for epoch 86/300
total_loss          0.5608
encoder_mse         0.0011
decoder_mse         0.3733
ber_loss            0.3733
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-86.pyt
Saving checkpoint done.

Starting epoch 87/300
Batch size = 32
Steps in epoch = 15
Epoch: 87/300 Step: 10/15
total_loss          0.6777
encoder_mse         0.0009
decoder_mse         0.4514
ber_loss            0.4514
----------------------------------------
Epoch: 87/300 Step: 15/15
total_loss          0.6505
encoder_mse         0.0009
decoder_mse         0.4332
ber_loss            0.4332
----------------------------------------
Epoch 87 training duration 10.25 sec
----------------------------------------
Running validation for epoch 87/300
total_loss          0.6624
encoder_mse         0.0011
decoder_mse         0.4411
ber_loss            0.4411
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-87.pyt
Saving checkpoint done.

Starting epoch 88/300
Batch size = 32
Steps in epoch = 15
Epoch: 88/300 Step: 10/15
total_loss          0.6009
encoder_mse         0.0010
decoder_mse         0.4001
ber_loss            0.4001
----------------------------------------
Epoch: 88/300 Step: 15/15
total_loss          0.6018
encoder_mse         0.0010
decoder_mse         0.4007
ber_loss            0.4007
----------------------------------------
Epoch 88 training duration 10.02 sec
----------------------------------------
Running validation for epoch 88/300
total_loss          0.6532
encoder_mse         0.0011
decoder_mse         0.4349
ber_loss            0.4349
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-88.pyt
Saving checkpoint done.

Starting epoch 89/300
Batch size = 32
Steps in epoch = 15
Epoch: 89/300 Step: 10/15
total_loss          0.4509
encoder_mse         0.0010
decoder_mse         0.3001
ber_loss            0.3001
----------------------------------------
Epoch: 89/300 Step: 15/15
total_loss          0.5494
encoder_mse         0.0010
decoder_mse         0.3658
ber_loss            0.3658
----------------------------------------
Epoch 89 training duration 9.93 sec
----------------------------------------
Running validation for epoch 89/300
total_loss          0.5637
encoder_mse         0.0011
decoder_mse         0.3753
ber_loss            0.3753
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-89.pyt
Saving checkpoint done.

Starting epoch 90/300
Batch size = 32
Steps in epoch = 15
Epoch: 90/300 Step: 10/15
total_loss          0.6048
encoder_mse         0.0010
decoder_mse         0.4027
ber_loss            0.4027
----------------------------------------
Epoch: 90/300 Step: 15/15
total_loss          0.6543
encoder_mse         0.0010
decoder_mse         0.4357
ber_loss            0.4357
----------------------------------------
Epoch 90 training duration 10.23 sec
----------------------------------------
Running validation for epoch 90/300
total_loss          0.4701
encoder_mse         0.0011
decoder_mse         0.3129
ber_loss            0.3129
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-90.pyt
Saving checkpoint done.

Starting epoch 91/300
Batch size = 32
Steps in epoch = 15
Epoch: 91/300 Step: 10/15
total_loss          0.3741
encoder_mse         0.0009
decoder_mse         0.2490
ber_loss            0.2490
----------------------------------------
Epoch: 91/300 Step: 15/15
total_loss          0.5013
encoder_mse         0.0009
decoder_mse         0.3338
ber_loss            0.3338
----------------------------------------
Epoch 91 training duration 10.32 sec
----------------------------------------
Running validation for epoch 91/300
total_loss          0.4688
encoder_mse         0.0011
decoder_mse         0.3120
ber_loss            0.3120
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-91.pyt
Saving checkpoint done.

Starting epoch 92/300
Batch size = 32
Steps in epoch = 15
Epoch: 92/300 Step: 10/15
total_loss          0.6727
encoder_mse         0.0010
decoder_mse         0.4480
ber_loss            0.4480
----------------------------------------
Epoch: 92/300 Step: 15/15
total_loss          0.5502
encoder_mse         0.0010
decoder_mse         0.3663
ber_loss            0.3663
----------------------------------------
Epoch 92 training duration 10.14 sec
----------------------------------------
Running validation for epoch 92/300
total_loss          0.4753
encoder_mse         0.0011
decoder_mse         0.3163
ber_loss            0.3163
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-92.pyt
Saving checkpoint done.

Starting epoch 93/300
Batch size = 32
Steps in epoch = 15
Epoch: 93/300 Step: 10/15
total_loss          0.5240
encoder_mse         0.0009
decoder_mse         0.3489
ber_loss            0.3489
----------------------------------------
Epoch: 93/300 Step: 15/15
total_loss          0.4996
encoder_mse         0.0009
decoder_mse         0.3327
ber_loss            0.3327
----------------------------------------
Epoch 93 training duration 10.41 sec
----------------------------------------
Running validation for epoch 93/300
total_loss          0.5674
encoder_mse         0.0011
decoder_mse         0.3777
ber_loss            0.3777
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-93.pyt
Saving checkpoint done.

Starting epoch 94/300
Batch size = 32
Steps in epoch = 15
Epoch: 94/300 Step: 10/15
total_loss          0.7502
encoder_mse         0.0009
decoder_mse         0.4997
ber_loss            0.4997
----------------------------------------
Epoch: 94/300 Step: 15/15
total_loss          0.7524
encoder_mse         0.0009
decoder_mse         0.5012
ber_loss            0.5012
----------------------------------------
Epoch 94 training duration 9.95 sec
----------------------------------------
Running validation for epoch 94/300
total_loss          0.7544
encoder_mse         0.0011
decoder_mse         0.5024
ber_loss            0.5024
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-94.pyt
Saving checkpoint done.

Starting epoch 95/300
Batch size = 32
Steps in epoch = 15
Epoch: 95/300 Step: 10/15
total_loss          0.5238
encoder_mse         0.0009
decoder_mse         0.3488
ber_loss            0.3488
----------------------------------------
Epoch: 95/300 Step: 15/15
total_loss          0.4996
encoder_mse         0.0010
decoder_mse         0.3326
ber_loss            0.3326
----------------------------------------
Epoch 95 training duration 10.25 sec
----------------------------------------
Running validation for epoch 95/300
total_loss          0.6627
encoder_mse         0.0011
decoder_mse         0.4413
ber_loss            0.4413
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-95.pyt
Saving checkpoint done.

Starting epoch 96/300
Batch size = 32
Steps in epoch = 15
Epoch: 96/300 Step: 10/15
total_loss          0.3736
encoder_mse         0.0010
decoder_mse         0.2486
ber_loss            0.2486
----------------------------------------
Epoch: 96/300 Step: 15/15
total_loss          0.4487
encoder_mse         0.0010
decoder_mse         0.2987
ber_loss            0.2987
----------------------------------------
Epoch 96 training duration 9.93 sec
----------------------------------------
Running validation for epoch 96/300
total_loss          0.7530
encoder_mse         0.0011
decoder_mse         0.5015
ber_loss            0.5015
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-96.pyt
Saving checkpoint done.

Starting epoch 97/300
Batch size = 32
Steps in epoch = 15
Epoch: 97/300 Step: 10/15
total_loss          0.7529
encoder_mse         0.0009
decoder_mse         0.5015
ber_loss            0.5015
----------------------------------------
Epoch: 97/300 Step: 15/15
total_loss          0.7034
encoder_mse         0.0009
decoder_mse         0.4685
ber_loss            0.4685
----------------------------------------
Epoch 97 training duration 10.14 sec
----------------------------------------
Running validation for epoch 97/300
total_loss          0.6666
encoder_mse         0.0011
decoder_mse         0.4439
ber_loss            0.4439
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-97.pyt
Saving checkpoint done.

Starting epoch 98/300
Batch size = 32
Steps in epoch = 15
Epoch: 98/300 Step: 10/15
total_loss          0.6725
encoder_mse         0.0009
decoder_mse         0.4479
ber_loss            0.4479
----------------------------------------
Epoch: 98/300 Step: 15/15
total_loss          0.7006
encoder_mse         0.0009
decoder_mse         0.4666
ber_loss            0.4666
----------------------------------------
Epoch 98 training duration 10.07 sec
----------------------------------------
Running validation for epoch 98/300
total_loss          0.6572
encoder_mse         0.0011
decoder_mse         0.4376
ber_loss            0.4376
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-98.pyt
Saving checkpoint done.

Starting epoch 99/300
Batch size = 32
Steps in epoch = 15
Epoch: 99/300 Step: 10/15
total_loss          0.6052
encoder_mse         0.0009
decoder_mse         0.4031
ber_loss            0.4031
----------------------------------------
Epoch: 99/300 Step: 15/15
total_loss          0.6541
encoder_mse         0.0009
decoder_mse         0.4357
ber_loss            0.4357
----------------------------------------
Epoch 99 training duration 10.49 sec
----------------------------------------
Running validation for epoch 99/300
total_loss          0.6562
encoder_mse         0.0011
decoder_mse         0.4370
ber_loss            0.4370
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-99.pyt
Saving checkpoint done.

Starting epoch 100/300
Batch size = 32
Steps in epoch = 15
Epoch: 100/300 Step: 10/15
total_loss          0.5970
encoder_mse         0.0010
decoder_mse         0.3975
ber_loss            0.3975
----------------------------------------
Epoch: 100/300 Step: 15/15
total_loss          0.6485
encoder_mse         0.0009
decoder_mse         0.4319
ber_loss            0.4319
----------------------------------------
Epoch 100 training duration 10.15 sec
----------------------------------------
Running validation for epoch 100/300
total_loss          0.6562
encoder_mse         0.0011
decoder_mse         0.4369
ber_loss            0.4369
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-100.pyt
Saving checkpoint done.

Starting epoch 101/300
Batch size = 32
Steps in epoch = 15
Epoch: 101/300 Step: 10/15
total_loss          0.6726
encoder_mse         0.0009
decoder_mse         0.4480
ber_loss            0.4480
----------------------------------------
Epoch: 101/300 Step: 15/15
total_loss          0.6483
encoder_mse         0.0009
decoder_mse         0.4318
ber_loss            0.4318
----------------------------------------
Epoch 101 training duration 10.27 sec
----------------------------------------
Running validation for epoch 101/300
total_loss          0.5661
encoder_mse         0.0011
decoder_mse         0.3769
ber_loss            0.3769
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-101.pyt
Saving checkpoint done.

Starting epoch 102/300
Batch size = 32
Steps in epoch = 15
Epoch: 102/300 Step: 10/15
total_loss          0.6007
encoder_mse         0.0009
decoder_mse         0.4000
ber_loss            0.4000
----------------------------------------
Epoch: 102/300 Step: 15/15
total_loss          0.6520
encoder_mse         0.0010
decoder_mse         0.4342
ber_loss            0.4342
----------------------------------------
Epoch 102 training duration 9.79 sec
----------------------------------------
Running validation for epoch 102/300
total_loss          0.4706
encoder_mse         0.0011
decoder_mse         0.3132
ber_loss            0.3132
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-102.pyt
Saving checkpoint done.

Starting epoch 103/300
Batch size = 32
Steps in epoch = 15
Epoch: 103/300 Step: 10/15
total_loss          0.6044
encoder_mse         0.0009
decoder_mse         0.4025
ber_loss            0.4025
----------------------------------------
Epoch: 103/300 Step: 15/15
total_loss          0.6014
encoder_mse         0.0009
decoder_mse         0.4005
ber_loss            0.4005
----------------------------------------
Epoch 103 training duration 10.21 sec
----------------------------------------
Running validation for epoch 103/300
total_loss          0.4722
encoder_mse         0.0011
decoder_mse         0.3143
ber_loss            0.3143
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-103.pyt
Saving checkpoint done.

Starting epoch 104/300
Batch size = 32
Steps in epoch = 15
Epoch: 104/300 Step: 10/15
total_loss          0.6035
encoder_mse         0.0009
decoder_mse         0.4019
ber_loss            0.4019
----------------------------------------
Epoch: 104/300 Step: 15/15
total_loss          0.6012
encoder_mse         0.0009
decoder_mse         0.4004
ber_loss            0.4004
----------------------------------------
Epoch 104 training duration 10.23 sec
----------------------------------------
Running validation for epoch 104/300
total_loss          0.7468
encoder_mse         0.0011
decoder_mse         0.4973
ber_loss            0.4973
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-104.pyt
Saving checkpoint done.

Starting epoch 105/300
Batch size = 32
Steps in epoch = 15
Epoch: 105/300 Step: 10/15
total_loss          0.7527
encoder_mse         0.0009
decoder_mse         0.5014
ber_loss            0.5014
----------------------------------------
Epoch: 105/300 Step: 15/15
total_loss          0.7527
encoder_mse         0.0009
decoder_mse         0.5014
ber_loss            0.5014
----------------------------------------
Epoch 105 training duration 10.13 sec
----------------------------------------
Running validation for epoch 105/300
total_loss          0.4648
encoder_mse         0.0011
decoder_mse         0.3094
ber_loss            0.3094
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-105.pyt
Saving checkpoint done.

Starting epoch 106/300
Batch size = 32
Steps in epoch = 15
Epoch: 106/300 Step: 10/15
total_loss          0.7536
encoder_mse         0.0009
decoder_mse         0.5020
ber_loss            0.5020
----------------------------------------
Epoch: 106/300 Step: 15/15
total_loss          0.6498
encoder_mse         0.0009
decoder_mse         0.4328
ber_loss            0.4328
----------------------------------------
Epoch 106 training duration 9.95 sec
----------------------------------------
Running validation for epoch 106/300
total_loss          0.4738
encoder_mse         0.0011
decoder_mse         0.3154
ber_loss            0.3154
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-106.pyt
Saving checkpoint done.

Starting epoch 107/300
Batch size = 32
Steps in epoch = 15
Epoch: 107/300 Step: 10/15
total_loss          0.6062
encoder_mse         0.0010
decoder_mse         0.4037
ber_loss            0.4037
----------------------------------------
Epoch: 107/300 Step: 15/15
total_loss          0.6077
encoder_mse         0.0009
decoder_mse         0.4047
ber_loss            0.4047
----------------------------------------
Epoch 107 training duration 10.02 sec
----------------------------------------
Running validation for epoch 107/300
total_loss          0.5657
encoder_mse         0.0011
decoder_mse         0.3766
ber_loss            0.3766
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-107.pyt
Saving checkpoint done.

Starting epoch 108/300
Batch size = 32
Steps in epoch = 15
Epoch: 108/300 Step: 10/15
total_loss          0.5280
encoder_mse         0.0010
decoder_mse         0.3516
ber_loss            0.3516
----------------------------------------
Epoch: 108/300 Step: 15/15
total_loss          0.5533
encoder_mse         0.0009
decoder_mse         0.3684
ber_loss            0.3684
----------------------------------------
Epoch 108 training duration 10.51 sec
----------------------------------------
Running validation for epoch 108/300
total_loss          0.3776
encoder_mse         0.0011
decoder_mse         0.2512
ber_loss            0.2512
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-108.pyt
Saving checkpoint done.

Starting epoch 109/300
Batch size = 32
Steps in epoch = 15
Epoch: 109/300 Step: 10/15
total_loss          0.5943
encoder_mse         0.0009
decoder_mse         0.3958
ber_loss            0.3958
----------------------------------------
Epoch: 109/300 Step: 15/15
total_loss          0.5976
encoder_mse         0.0009
decoder_mse         0.3980
ber_loss            0.3980
----------------------------------------
Epoch 109 training duration 10.26 sec
----------------------------------------
Running validation for epoch 109/300
total_loss          0.6605
encoder_mse         0.0011
decoder_mse         0.4398
ber_loss            0.4398
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-109.pyt
Saving checkpoint done.

Starting epoch 110/300
Batch size = 32
Steps in epoch = 15
Epoch: 110/300 Step: 10/15
total_loss          0.6767
encoder_mse         0.0009
decoder_mse         0.4507
ber_loss            0.4507
----------------------------------------
Epoch: 110/300 Step: 15/15
total_loss          0.6514
encoder_mse         0.0009
decoder_mse         0.4338
ber_loss            0.4338
----------------------------------------
Epoch 110 training duration 10.25 sec
----------------------------------------
Running validation for epoch 110/300
total_loss          0.6579
encoder_mse         0.0011
decoder_mse         0.4381
ber_loss            0.4381
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-110.pyt
Saving checkpoint done.

Starting epoch 111/300
Batch size = 32
Steps in epoch = 15
Epoch: 111/300 Step: 10/15
total_loss          0.7522
encoder_mse         0.0009
decoder_mse         0.5010
ber_loss            0.5010
----------------------------------------
Epoch: 111/300 Step: 15/15
total_loss          0.6519
encoder_mse         0.0009
decoder_mse         0.4342
ber_loss            0.4342
----------------------------------------
Epoch 111 training duration 10.21 sec
----------------------------------------
Running validation for epoch 111/300
total_loss          0.6611
encoder_mse         0.0011
decoder_mse         0.4402
ber_loss            0.4402
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-111.pyt
Saving checkpoint done.

Starting epoch 112/300
Batch size = 32
Steps in epoch = 15
Epoch: 112/300 Step: 10/15
total_loss          0.6745
encoder_mse         0.0009
decoder_mse         0.4492
ber_loss            0.4492
----------------------------------------
Epoch: 112/300 Step: 15/15
total_loss          0.5981
encoder_mse         0.0009
decoder_mse         0.3983
ber_loss            0.3983
----------------------------------------
Epoch 112 training duration 10.03 sec
----------------------------------------
Running validation for epoch 112/300
total_loss          0.7525
encoder_mse         0.0011
decoder_mse         0.5011
ber_loss            0.5011
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-112.pyt
Saving checkpoint done.

Starting epoch 113/300
Batch size = 32
Steps in epoch = 15
Epoch: 113/300 Step: 10/15
total_loss          0.6782
encoder_mse         0.0009
decoder_mse         0.4517
ber_loss            0.4517
----------------------------------------
Epoch: 113/300 Step: 15/15
total_loss          0.5528
encoder_mse         0.0009
decoder_mse         0.3681
ber_loss            0.3681
----------------------------------------
Epoch 113 training duration 10.49 sec
----------------------------------------
Running validation for epoch 113/300
total_loss          0.5630
encoder_mse         0.0011
decoder_mse         0.3748
ber_loss            0.3748
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-113.pyt
Saving checkpoint done.

Starting epoch 114/300
Batch size = 32
Steps in epoch = 15
Epoch: 114/300 Step: 10/15
total_loss          0.6047
encoder_mse         0.0010
decoder_mse         0.4027
ber_loss            0.4027
----------------------------------------
Epoch: 114/300 Step: 15/15
total_loss          0.6046
encoder_mse         0.0010
decoder_mse         0.4026
ber_loss            0.4026
----------------------------------------
Epoch 114 training duration 10.54 sec
----------------------------------------
Running validation for epoch 114/300
total_loss          0.5662
encoder_mse         0.0011
decoder_mse         0.3770
ber_loss            0.3770
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-114.pyt
Saving checkpoint done.

Starting epoch 115/300
Batch size = 32
Steps in epoch = 15
Epoch: 115/300 Step: 10/15
total_loss          0.5318
encoder_mse         0.0009
decoder_mse         0.3541
ber_loss            0.3541
----------------------------------------
Epoch: 115/300 Step: 15/15
total_loss          0.5557
encoder_mse         0.0009
decoder_mse         0.3700
ber_loss            0.3700
----------------------------------------
Epoch 115 training duration 9.77 sec
----------------------------------------
Running validation for epoch 115/300
total_loss          0.5615
encoder_mse         0.0011
decoder_mse         0.3738
ber_loss            0.3738
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-115.pyt
Saving checkpoint done.

Starting epoch 116/300
Batch size = 32
Steps in epoch = 15
Epoch: 116/300 Step: 10/15
total_loss          0.6027
encoder_mse         0.0009
decoder_mse         0.4013
ber_loss            0.4013
----------------------------------------
Epoch: 116/300 Step: 15/15
total_loss          0.6570
encoder_mse         0.0009
decoder_mse         0.4376
ber_loss            0.4376
----------------------------------------
Epoch 116 training duration 10.22 sec
----------------------------------------
Running validation for epoch 116/300
total_loss          0.7497
encoder_mse         0.0011
decoder_mse         0.4993
ber_loss            0.4993
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-116.pyt
Saving checkpoint done.

Starting epoch 117/300
Batch size = 32
Steps in epoch = 15
Epoch: 117/300 Step: 10/15
total_loss          0.3726
encoder_mse         0.0009
decoder_mse         0.2480
ber_loss            0.2480
----------------------------------------
Epoch: 117/300 Step: 15/15
total_loss          0.4485
encoder_mse         0.0009
decoder_mse         0.2986
ber_loss            0.2986
----------------------------------------
Epoch 117 training duration 10.06 sec
----------------------------------------
Running validation for epoch 117/300
total_loss          0.6631
encoder_mse         0.0011
decoder_mse         0.4416
ber_loss            0.4416
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-117.pyt
Saving checkpoint done.

Starting epoch 118/300
Batch size = 32
Steps in epoch = 15
Epoch: 118/300 Step: 10/15
total_loss          0.6011
encoder_mse         0.0010
decoder_mse         0.4002
ber_loss            0.4002
----------------------------------------
Epoch: 118/300 Step: 15/15
total_loss          0.5537
encoder_mse         0.0010
decoder_mse         0.3687
ber_loss            0.3687
----------------------------------------
Epoch 118 training duration 10.20 sec
----------------------------------------
Running validation for epoch 118/300
total_loss          0.6607
encoder_mse         0.0011
decoder_mse         0.4399
ber_loss            0.4399
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-118.pyt
Saving checkpoint done.

Starting epoch 119/300
Batch size = 32
Steps in epoch = 15
Epoch: 119/300 Step: 10/15
total_loss          0.7505
encoder_mse         0.0010
decoder_mse         0.4999
ber_loss            0.4999
----------------------------------------
Epoch: 119/300 Step: 15/15
total_loss          0.6986
encoder_mse         0.0010
decoder_mse         0.4653
ber_loss            0.4653
----------------------------------------
Epoch 119 training duration 10.17 sec
----------------------------------------
Running validation for epoch 119/300
total_loss          0.7510
encoder_mse         0.0011
decoder_mse         0.5001
ber_loss            0.5001
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-119.pyt
Saving checkpoint done.

Starting epoch 120/300
Batch size = 32
Steps in epoch = 15
Epoch: 120/300 Step: 10/15
total_loss          0.5330
encoder_mse         0.0010
decoder_mse         0.3548
ber_loss            0.3548
----------------------------------------
Epoch: 120/300 Step: 15/15
total_loss          0.6071
encoder_mse         0.0010
decoder_mse         0.4042
ber_loss            0.4042
----------------------------------------
Epoch 120 training duration 10.19 sec
----------------------------------------
Running validation for epoch 120/300
total_loss          0.7509
encoder_mse         0.0011
decoder_mse         0.5001
ber_loss            0.5001
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-120.pyt
Saving checkpoint done.

Starting epoch 121/300
Batch size = 32
Steps in epoch = 15
Epoch: 121/300 Step: 10/15
total_loss          0.5997
encoder_mse         0.0009
decoder_mse         0.3994
ber_loss            0.3994
----------------------------------------
Epoch: 121/300 Step: 15/15
total_loss          0.5512
encoder_mse         0.0009
decoder_mse         0.3671
ber_loss            0.3671
----------------------------------------
Epoch 121 training duration 10.51 sec
----------------------------------------
Running validation for epoch 121/300
total_loss          0.5620
encoder_mse         0.0011
decoder_mse         0.3741
ber_loss            0.3741
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-121.pyt
Saving checkpoint done.

Starting epoch 122/300
Batch size = 32
Steps in epoch = 15
Epoch: 122/300 Step: 10/15
total_loss          0.6795
encoder_mse         0.0009
decoder_mse         0.4526
ber_loss            0.4526
----------------------------------------
Epoch: 122/300 Step: 15/15
total_loss          0.7037
encoder_mse         0.0009
decoder_mse         0.4687
ber_loss            0.4687
----------------------------------------
Epoch 122 training duration 10.36 sec
----------------------------------------
Running validation for epoch 122/300
total_loss          0.7510
encoder_mse         0.0011
decoder_mse         0.5001
ber_loss            0.5001
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-122.pyt
Saving checkpoint done.

Starting epoch 123/300
Batch size = 32
Steps in epoch = 15
Epoch: 123/300 Step: 10/15
total_loss          0.5976
encoder_mse         0.0009
decoder_mse         0.3980
ber_loss            0.3980
----------------------------------------
Epoch: 123/300 Step: 15/15
total_loss          0.5489
encoder_mse         0.0009
decoder_mse         0.3655
ber_loss            0.3655
----------------------------------------
Epoch 123 training duration 10.34 sec
----------------------------------------
Running validation for epoch 123/300
total_loss          0.4722
encoder_mse         0.0011
decoder_mse         0.3143
ber_loss            0.3143
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-123.pyt
Saving checkpoint done.

Starting epoch 124/300
Batch size = 32
Steps in epoch = 15
Epoch: 124/300 Step: 10/15
total_loss          0.6790
encoder_mse         0.0010
decoder_mse         0.4522
ber_loss            0.4522
----------------------------------------
Epoch: 124/300 Step: 15/15
total_loss          0.7010
encoder_mse         0.0009
decoder_mse         0.4669
ber_loss            0.4669
----------------------------------------
Epoch 124 training duration 9.98 sec
----------------------------------------
Running validation for epoch 124/300
total_loss          0.6644
encoder_mse         0.0011
decoder_mse         0.4424
ber_loss            0.4424
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-124.pyt
Saving checkpoint done.

Starting epoch 125/300
Batch size = 32
Steps in epoch = 15
Epoch: 125/300 Step: 10/15
total_loss          0.3714
encoder_mse         0.0010
decoder_mse         0.2471
ber_loss            0.2471
----------------------------------------
Epoch: 125/300 Step: 15/15
total_loss          0.3997
encoder_mse         0.0009
decoder_mse         0.2660
ber_loss            0.2660
----------------------------------------
Epoch 125 training duration 10.01 sec
----------------------------------------
Running validation for epoch 125/300
total_loss          0.6570
encoder_mse         0.0011
decoder_mse         0.4375
ber_loss            0.4375
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-125.pyt
Saving checkpoint done.

Starting epoch 126/300
Batch size = 32
Steps in epoch = 15
Epoch: 126/300 Step: 10/15
total_loss          0.5300
encoder_mse         0.0009
decoder_mse         0.3529
ber_loss            0.3529
----------------------------------------
Epoch: 126/300 Step: 15/15
total_loss          0.5528
encoder_mse         0.0009
decoder_mse         0.3681
ber_loss            0.3681
----------------------------------------
Epoch 126 training duration 10.09 sec
----------------------------------------
Running validation for epoch 126/300
total_loss          0.5639
encoder_mse         0.0011
decoder_mse         0.3754
ber_loss            0.3754
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-126.pyt
Saving checkpoint done.

Starting epoch 127/300
Batch size = 32
Steps in epoch = 15
Epoch: 127/300 Step: 10/15
total_loss          0.6795
encoder_mse         0.0009
decoder_mse         0.4526
ber_loss            0.4526
----------------------------------------
Epoch: 127/300 Step: 15/15
total_loss          0.5522
encoder_mse         0.0009
decoder_mse         0.3677
ber_loss            0.3677
----------------------------------------
Epoch 127 training duration 10.31 sec
----------------------------------------
Running validation for epoch 127/300
total_loss          0.7451
encoder_mse         0.0011
decoder_mse         0.4962
ber_loss            0.4962
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-127.pyt
Saving checkpoint done.

Starting epoch 128/300
Batch size = 32
Steps in epoch = 15
Epoch: 128/300 Step: 10/15
total_loss          0.7535
encoder_mse         0.0009
decoder_mse         0.5019
ber_loss            0.5019
----------------------------------------
Epoch: 128/300 Step: 15/15
total_loss          0.7524
encoder_mse         0.0009
decoder_mse         0.5012
ber_loss            0.5012
----------------------------------------
Epoch 128 training duration 10.55 sec
----------------------------------------
Running validation for epoch 128/300
total_loss          0.7429
encoder_mse         0.0011
decoder_mse         0.4947
ber_loss            0.4947
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-128.pyt
Saving checkpoint done.

Starting epoch 129/300
Batch size = 32
Steps in epoch = 15
Epoch: 129/300 Step: 10/15
total_loss          0.6822
encoder_mse         0.0009
decoder_mse         0.4543
ber_loss            0.4543
----------------------------------------
Epoch: 129/300 Step: 15/15
total_loss          0.6552
encoder_mse         0.0009
decoder_mse         0.4364
ber_loss            0.4364
----------------------------------------
Epoch 129 training duration 10.25 sec
----------------------------------------
Running validation for epoch 129/300
total_loss          0.7482
encoder_mse         0.0011
decoder_mse         0.4983
ber_loss            0.4983
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-129.pyt
Saving checkpoint done.

Starting epoch 130/300
Batch size = 32
Steps in epoch = 15
Epoch: 130/300 Step: 10/15
total_loss          0.7465
encoder_mse         0.0010
decoder_mse         0.4972
ber_loss            0.4972
----------------------------------------
Epoch: 130/300 Step: 15/15
total_loss          0.6973
encoder_mse         0.0009
decoder_mse         0.4645
ber_loss            0.4645
----------------------------------------
Epoch 130 training duration 10.37 sec
----------------------------------------
Running validation for epoch 130/300
total_loss          0.6654
encoder_mse         0.0011
decoder_mse         0.4431
ber_loss            0.4431
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-130.pyt
Saving checkpoint done.

Starting epoch 131/300
Batch size = 32
Steps in epoch = 15
Epoch: 131/300 Step: 10/15
total_loss          0.5223
encoder_mse         0.0010
decoder_mse         0.3478
ber_loss            0.3478
----------------------------------------
Epoch: 131/300 Step: 15/15
total_loss          0.4487
encoder_mse         0.0009
decoder_mse         0.2987
ber_loss            0.2987
----------------------------------------
Epoch 131 training duration 10.15 sec
----------------------------------------
Running validation for epoch 131/300
total_loss          0.6589
encoder_mse         0.0011
decoder_mse         0.4387
ber_loss            0.4387
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-131.pyt
Saving checkpoint done.

Starting epoch 132/300
Batch size = 32
Steps in epoch = 15
Epoch: 132/300 Step: 10/15
total_loss          0.5998
encoder_mse         0.0010
decoder_mse         0.3994
ber_loss            0.3994
----------------------------------------
Epoch: 132/300 Step: 15/15
total_loss          0.6007
encoder_mse         0.0009
decoder_mse         0.4000
ber_loss            0.4000
----------------------------------------
Epoch 132 training duration 9.99 sec
----------------------------------------
Running validation for epoch 132/300
total_loss          0.7528
encoder_mse         0.0011
decoder_mse         0.5014
ber_loss            0.5014
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-132.pyt
Saving checkpoint done.

Starting epoch 133/300
Batch size = 32
Steps in epoch = 15
Epoch: 133/300 Step: 10/15
total_loss          0.6019
encoder_mse         0.0010
decoder_mse         0.4008
ber_loss            0.4008
----------------------------------------
Epoch: 133/300 Step: 15/15
total_loss          0.6499
encoder_mse         0.0010
decoder_mse         0.4328
ber_loss            0.4328
----------------------------------------
Epoch 133 training duration 10.17 sec
----------------------------------------
Running validation for epoch 133/300
total_loss          0.6556
encoder_mse         0.0011
decoder_mse         0.4365
ber_loss            0.4365
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-133.pyt
Saving checkpoint done.

Starting epoch 134/300
Batch size = 32
Steps in epoch = 15
Epoch: 134/300 Step: 10/15
total_loss          0.5277
encoder_mse         0.0009
decoder_mse         0.3514
ber_loss            0.3514
----------------------------------------
Epoch: 134/300 Step: 15/15
total_loss          0.5539
encoder_mse         0.0009
decoder_mse         0.3689
ber_loss            0.3689
----------------------------------------
Epoch 134 training duration 10.33 sec
----------------------------------------
Running validation for epoch 134/300
total_loss          0.5656
encoder_mse         0.0011
decoder_mse         0.3765
ber_loss            0.3765
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-134.pyt
Saving checkpoint done.

Starting epoch 135/300
Batch size = 32
Steps in epoch = 15
Epoch: 135/300 Step: 10/15
total_loss          0.5980
encoder_mse         0.0009
decoder_mse         0.3982
ber_loss            0.3982
----------------------------------------
Epoch: 135/300 Step: 15/15
total_loss          0.6003
encoder_mse         0.0009
decoder_mse         0.3998
ber_loss            0.3998
----------------------------------------
Epoch 135 training duration 10.41 sec
----------------------------------------
Running validation for epoch 135/300
total_loss          0.7591
encoder_mse         0.0011
decoder_mse         0.5055
ber_loss            0.5055
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-135.pyt
Saving checkpoint done.

Starting epoch 136/300
Batch size = 32
Steps in epoch = 15
Epoch: 136/300 Step: 10/15
total_loss          0.6782
encoder_mse         0.0009
decoder_mse         0.4517
ber_loss            0.4517
----------------------------------------
Epoch: 136/300 Step: 15/15
total_loss          0.6017
encoder_mse         0.0009
decoder_mse         0.4007
ber_loss            0.4007
----------------------------------------
Epoch 136 training duration 10.23 sec
----------------------------------------
Running validation for epoch 136/300
total_loss          0.7538
encoder_mse         0.0011
decoder_mse         0.5020
ber_loss            0.5020
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-136.pyt
Saving checkpoint done.

Starting epoch 137/300
Batch size = 32
Steps in epoch = 15
Epoch: 137/300 Step: 10/15
total_loss          0.5264
encoder_mse         0.0009
decoder_mse         0.3505
ber_loss            0.3505
----------------------------------------
Epoch: 137/300 Step: 15/15
total_loss          0.5020
encoder_mse         0.0010
decoder_mse         0.3342
ber_loss            0.3342
----------------------------------------
Epoch 137 training duration 9.84 sec
----------------------------------------
Running validation for epoch 137/300
total_loss          0.6594
encoder_mse         0.0011
decoder_mse         0.4391
ber_loss            0.4391
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-137.pyt
Saving checkpoint done.

Starting epoch 138/300
Batch size = 32
Steps in epoch = 15
Epoch: 138/300 Step: 10/15
total_loss          0.5261
encoder_mse         0.0009
decoder_mse         0.3503
ber_loss            0.3503
----------------------------------------
Epoch: 138/300 Step: 15/15
total_loss          0.5489
encoder_mse         0.0009
decoder_mse         0.3655
ber_loss            0.3655
----------------------------------------
Epoch 138 training duration 10.09 sec
----------------------------------------
Running validation for epoch 138/300
total_loss          0.7500
encoder_mse         0.0011
decoder_mse         0.4995
ber_loss            0.4995
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-138.pyt
Saving checkpoint done.

Starting epoch 139/300
Batch size = 32
Steps in epoch = 15
Epoch: 139/300 Step: 10/15
total_loss          0.6817
encoder_mse         0.0009
decoder_mse         0.4541
ber_loss            0.4541
----------------------------------------
Epoch: 139/300 Step: 15/15
total_loss          0.6047
encoder_mse         0.0009
decoder_mse         0.4027
ber_loss            0.4027
----------------------------------------
Epoch 139 training duration 10.20 sec
----------------------------------------
Running validation for epoch 139/300
total_loss          0.5712
encoder_mse         0.0011
decoder_mse         0.3803
ber_loss            0.3803
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-139.pyt
Saving checkpoint done.

Starting epoch 140/300
Batch size = 32
Steps in epoch = 15
Epoch: 140/300 Step: 10/15
total_loss          0.6701
encoder_mse         0.0009
decoder_mse         0.4463
ber_loss            0.4463
----------------------------------------
Epoch: 140/300 Step: 15/15
total_loss          0.6504
encoder_mse         0.0010
decoder_mse         0.4331
ber_loss            0.4331
----------------------------------------
Epoch 140 training duration 10.09 sec
----------------------------------------
Running validation for epoch 140/300
total_loss          0.7579
encoder_mse         0.0011
decoder_mse         0.5047
ber_loss            0.5047
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-140.pyt
Saving checkpoint done.

Starting epoch 141/300
Batch size = 32
Steps in epoch = 15
Epoch: 141/300 Step: 10/15
total_loss          0.5988
encoder_mse         0.0009
decoder_mse         0.3988
ber_loss            0.3988
----------------------------------------
Epoch: 141/300 Step: 15/15
total_loss          0.6511
encoder_mse         0.0009
decoder_mse         0.4336
ber_loss            0.4336
----------------------------------------
Epoch 141 training duration 10.42 sec
----------------------------------------
Running validation for epoch 141/300
total_loss          0.7478
encoder_mse         0.0011
decoder_mse         0.4980
ber_loss            0.4980
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-141.pyt
Saving checkpoint done.

Starting epoch 142/300
Batch size = 32
Steps in epoch = 15
Epoch: 142/300 Step: 10/15
total_loss          0.6730
encoder_mse         0.0009
decoder_mse         0.4482
ber_loss            0.4482
----------------------------------------
Epoch: 142/300 Step: 15/15
total_loss          0.6993
encoder_mse         0.0010
decoder_mse         0.4658
ber_loss            0.4658
----------------------------------------
Epoch 142 training duration 9.82 sec
----------------------------------------
Running validation for epoch 142/300
total_loss          0.6591
encoder_mse         0.0011
decoder_mse         0.4389
ber_loss            0.4389
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-142.pyt
Saving checkpoint done.

Starting epoch 143/300
Batch size = 32
Steps in epoch = 15
Epoch: 143/300 Step: 10/15
total_loss          0.7548
encoder_mse         0.0010
decoder_mse         0.5027
ber_loss            0.5027
----------------------------------------
Epoch: 143/300 Step: 15/15
total_loss          0.7544
encoder_mse         0.0010
decoder_mse         0.5025
ber_loss            0.5025
----------------------------------------
Epoch 143 training duration 10.19 sec
----------------------------------------
Running validation for epoch 143/300
total_loss          0.5707
encoder_mse         0.0011
decoder_mse         0.3800
ber_loss            0.3800
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-143.pyt
Saving checkpoint done.

Starting epoch 144/300
Batch size = 32
Steps in epoch = 15
Epoch: 144/300 Step: 10/15
total_loss          0.4510
encoder_mse         0.0009
decoder_mse         0.3003
ber_loss            0.3003
----------------------------------------
Epoch: 144/300 Step: 15/15
total_loss          0.5509
encoder_mse         0.0009
decoder_mse         0.3668
ber_loss            0.3668
----------------------------------------
Epoch 144 training duration 10.19 sec
----------------------------------------
Running validation for epoch 144/300
total_loss          0.7602
encoder_mse         0.0011
decoder_mse         0.5063
ber_loss            0.5063
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-144.pyt
Saving checkpoint done.

Starting epoch 145/300
Batch size = 32
Steps in epoch = 15
Epoch: 145/300 Step: 10/15
total_loss          0.6007
encoder_mse         0.0010
decoder_mse         0.4000
ber_loss            0.4000
----------------------------------------
Epoch: 145/300 Step: 15/15
total_loss          0.5516
encoder_mse         0.0010
decoder_mse         0.3673
ber_loss            0.3673
----------------------------------------
Epoch 145 training duration 10.62 sec
----------------------------------------
Running validation for epoch 145/300
total_loss          0.4714
encoder_mse         0.0011
decoder_mse         0.3137
ber_loss            0.3137
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-145.pyt
Saving checkpoint done.

Starting epoch 146/300
Batch size = 32
Steps in epoch = 15
Epoch: 146/300 Step: 10/15
total_loss          0.4502
encoder_mse         0.0009
decoder_mse         0.2997
ber_loss            0.2997
----------------------------------------
Epoch: 146/300 Step: 15/15
total_loss          0.4996
encoder_mse         0.0009
decoder_mse         0.3326
ber_loss            0.3326
----------------------------------------
Epoch 146 training duration 10.15 sec
----------------------------------------
Running validation for epoch 146/300
total_loss          0.7585
encoder_mse         0.0011
decoder_mse         0.5052
ber_loss            0.5052
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-146.pyt
Saving checkpoint done.

Starting epoch 147/300
Batch size = 32
Steps in epoch = 15
Epoch: 147/300 Step: 10/15
total_loss          0.5252
encoder_mse         0.0009
decoder_mse         0.3497
ber_loss            0.3497
----------------------------------------
Epoch: 147/300 Step: 15/15
total_loss          0.4995
encoder_mse         0.0009
decoder_mse         0.3326
ber_loss            0.3326
----------------------------------------
Epoch 147 training duration 10.20 sec
----------------------------------------
Running validation for epoch 147/300
total_loss          0.7539
encoder_mse         0.0011
decoder_mse         0.5021
ber_loss            0.5021
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-147.pyt
Saving checkpoint done.

Starting epoch 148/300
Batch size = 32
Steps in epoch = 15
Epoch: 148/300 Step: 10/15
total_loss          0.5985
encoder_mse         0.0009
decoder_mse         0.3986
ber_loss            0.3986
----------------------------------------
Epoch: 148/300 Step: 15/15
total_loss          0.5497
encoder_mse         0.0009
decoder_mse         0.3660
ber_loss            0.3660
----------------------------------------
Epoch 148 training duration 10.55 sec
----------------------------------------
Running validation for epoch 148/300
total_loss          0.2863
encoder_mse         0.0011
decoder_mse         0.1904
ber_loss            0.1904
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-148.pyt
Saving checkpoint done.

Starting epoch 149/300
Batch size = 32
Steps in epoch = 15
Epoch: 149/300 Step: 10/15
total_loss          0.5221
encoder_mse         0.0009
decoder_mse         0.3476
ber_loss            0.3476
----------------------------------------
Epoch: 149/300 Step: 15/15
total_loss          0.5487
encoder_mse         0.0010
decoder_mse         0.3653
ber_loss            0.3653
----------------------------------------
Epoch 149 training duration 10.13 sec
----------------------------------------
Running validation for epoch 149/300
total_loss          0.5632
encoder_mse         0.0011
decoder_mse         0.3749
ber_loss            0.3749
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-149.pyt
Saving checkpoint done.

Starting epoch 150/300
Batch size = 32
Steps in epoch = 15
Epoch: 150/300 Step: 10/15
total_loss          0.6027
encoder_mse         0.0010
decoder_mse         0.4014
ber_loss            0.4014
----------------------------------------
Epoch: 150/300 Step: 15/15
total_loss          0.5513
encoder_mse         0.0010
decoder_mse         0.3671
ber_loss            0.3671
----------------------------------------
Epoch 150 training duration 10.11 sec
----------------------------------------
Running validation for epoch 150/300
total_loss          0.4660
encoder_mse         0.0011
decoder_mse         0.3102
ber_loss            0.3102
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-150.pyt
Saving checkpoint done.

Starting epoch 151/300
Batch size = 32
Steps in epoch = 15
Epoch: 151/300 Step: 10/15
total_loss          0.6791
encoder_mse         0.0009
decoder_mse         0.4523
ber_loss            0.4523
----------------------------------------
Epoch: 151/300 Step: 15/15
total_loss          0.6530
encoder_mse         0.0009
decoder_mse         0.4349
ber_loss            0.4349
----------------------------------------
Epoch 151 training duration 9.92 sec
----------------------------------------
Running validation for epoch 151/300
total_loss          0.6635
encoder_mse         0.0011
decoder_mse         0.4418
ber_loss            0.4418
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-151.pyt
Saving checkpoint done.

Starting epoch 152/300
Batch size = 32
Steps in epoch = 15
Epoch: 152/300 Step: 10/15
total_loss          0.6766
encoder_mse         0.0009
decoder_mse         0.4506
ber_loss            0.4506
----------------------------------------
Epoch: 152/300 Step: 15/15
total_loss          0.6512
encoder_mse         0.0009
decoder_mse         0.4337
ber_loss            0.4337
----------------------------------------
Epoch 152 training duration 10.11 sec
----------------------------------------
Running validation for epoch 152/300
total_loss          0.5684
encoder_mse         0.0011
decoder_mse         0.3784
ber_loss            0.3784
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-152.pyt
Saving checkpoint done.

Starting epoch 153/300
Batch size = 32
Steps in epoch = 15
Epoch: 153/300 Step: 10/15
total_loss          0.5233
encoder_mse         0.0010
decoder_mse         0.3484
ber_loss            0.3484
----------------------------------------
Epoch: 153/300 Step: 15/15
total_loss          0.5499
encoder_mse         0.0010
decoder_mse         0.3662
ber_loss            0.3662
----------------------------------------
Epoch 153 training duration 9.81 sec
----------------------------------------
Running validation for epoch 153/300
total_loss          0.4691
encoder_mse         0.0011
decoder_mse         0.3122
ber_loss            0.3122
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-153.pyt
Saving checkpoint done.

Starting epoch 154/300
Batch size = 32
Steps in epoch = 15
Epoch: 154/300 Step: 10/15
total_loss          0.5315
encoder_mse         0.0010
decoder_mse         0.3539
ber_loss            0.3539
----------------------------------------
Epoch: 154/300 Step: 15/15
total_loss          0.6049
encoder_mse         0.0009
decoder_mse         0.4028
ber_loss            0.4028
----------------------------------------
Epoch 154 training duration 10.24 sec
----------------------------------------
Running validation for epoch 154/300
total_loss          0.4714
encoder_mse         0.0011
decoder_mse         0.3138
ber_loss            0.3138
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-154.pyt
Saving checkpoint done.

Starting epoch 155/300
Batch size = 32
Steps in epoch = 15
Epoch: 155/300 Step: 10/15
total_loss          0.4509
encoder_mse         0.0009
decoder_mse         0.3002
ber_loss            0.3002
----------------------------------------
Epoch: 155/300 Step: 15/15
total_loss          0.5510
encoder_mse         0.0009
decoder_mse         0.3669
ber_loss            0.3669
----------------------------------------
Epoch 155 training duration 10.22 sec
----------------------------------------
Running validation for epoch 155/300
total_loss          0.6597
encoder_mse         0.0011
decoder_mse         0.4393
ber_loss            0.4393
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-155.pyt
Saving checkpoint done.

Starting epoch 156/300
Batch size = 32
Steps in epoch = 15
Epoch: 156/300 Step: 10/15
total_loss          0.7520
encoder_mse         0.0009
decoder_mse         0.5009
ber_loss            0.5009
----------------------------------------
Epoch: 156/300 Step: 15/15
total_loss          0.7029
encoder_mse         0.0009
decoder_mse         0.4682
ber_loss            0.4682
----------------------------------------
Epoch 156 training duration 10.25 sec
----------------------------------------
Running validation for epoch 156/300
total_loss          0.5659
encoder_mse         0.0011
decoder_mse         0.3767
ber_loss            0.3767
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-156.pyt
Saving checkpoint done.

Starting epoch 157/300
Batch size = 32
Steps in epoch = 15
Epoch: 157/300 Step: 10/15
total_loss          0.5968
encoder_mse         0.0009
decoder_mse         0.3974
ber_loss            0.3974
----------------------------------------
Epoch: 157/300 Step: 15/15
total_loss          0.6490
encoder_mse         0.0009
decoder_mse         0.4323
ber_loss            0.4323
----------------------------------------
Epoch 157 training duration 10.08 sec
----------------------------------------
Running validation for epoch 157/300
total_loss          0.5595
encoder_mse         0.0011
decoder_mse         0.3725
ber_loss            0.3725
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-157.pyt
Saving checkpoint done.

Starting epoch 158/300
Batch size = 32
Steps in epoch = 15
Epoch: 158/300 Step: 10/15
total_loss          0.6022
encoder_mse         0.0010
decoder_mse         0.4010
ber_loss            0.4010
----------------------------------------
Epoch: 158/300 Step: 15/15
total_loss          0.6010
encoder_mse         0.0010
decoder_mse         0.4002
ber_loss            0.4002
----------------------------------------
Epoch 158 training duration 10.22 sec
----------------------------------------
Running validation for epoch 158/300
total_loss          0.6565
encoder_mse         0.0011
decoder_mse         0.4371
ber_loss            0.4371
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-158.pyt
Saving checkpoint done.

Starting epoch 159/300
Batch size = 32
Steps in epoch = 15
Epoch: 159/300 Step: 10/15
total_loss          0.6008
encoder_mse         0.0009
decoder_mse         0.4001
ber_loss            0.4001
----------------------------------------
Epoch: 159/300 Step: 15/15
total_loss          0.6019
encoder_mse         0.0009
decoder_mse         0.4008
ber_loss            0.4008
----------------------------------------
Epoch 159 training duration 10.23 sec
----------------------------------------
Running validation for epoch 159/300
total_loss          0.5700
encoder_mse         0.0011
decoder_mse         0.3795
ber_loss            0.3795
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-159.pyt
Saving checkpoint done.

Starting epoch 160/300
Batch size = 32
Steps in epoch = 15
Epoch: 160/300 Step: 10/15
total_loss          0.7552
encoder_mse         0.0010
decoder_mse         0.5030
ber_loss            0.5030
----------------------------------------
Epoch: 160/300 Step: 15/15
total_loss          0.7561
encoder_mse         0.0010
decoder_mse         0.5036
ber_loss            0.5036
----------------------------------------
Epoch 160 training duration 10.03 sec
----------------------------------------
Running validation for epoch 160/300
total_loss          0.6569
encoder_mse         0.0011
decoder_mse         0.4374
ber_loss            0.4374
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-160.pyt
Saving checkpoint done.

Starting epoch 161/300
Batch size = 32
Steps in epoch = 15
Epoch: 161/300 Step: 10/15
total_loss          0.5947
encoder_mse         0.0009
decoder_mse         0.3960
ber_loss            0.3960
----------------------------------------
Epoch: 161/300 Step: 15/15
total_loss          0.6464
encoder_mse         0.0009
decoder_mse         0.4305
ber_loss            0.4305
----------------------------------------
Epoch 161 training duration 10.40 sec
----------------------------------------
Running validation for epoch 161/300
total_loss          0.4676
encoder_mse         0.0011
decoder_mse         0.3112
ber_loss            0.3112
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-161.pyt
Saving checkpoint done.

Starting epoch 162/300
Batch size = 32
Steps in epoch = 15
Epoch: 162/300 Step: 10/15
total_loss          0.5948
encoder_mse         0.0009
decoder_mse         0.3961
ber_loss            0.3961
----------------------------------------
Epoch: 162/300 Step: 15/15
total_loss          0.6417
encoder_mse         0.0009
decoder_mse         0.4274
ber_loss            0.4274
----------------------------------------
Epoch 162 training duration 10.11 sec
----------------------------------------
Running validation for epoch 162/300
total_loss          0.7530
encoder_mse         0.0011
decoder_mse         0.5015
ber_loss            0.5015
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-162.pyt
Saving checkpoint done.

Starting epoch 163/300
Batch size = 32
Steps in epoch = 15
Epoch: 163/300 Step: 10/15
total_loss          0.6766
encoder_mse         0.0009
decoder_mse         0.4507
ber_loss            0.4507
----------------------------------------
Epoch: 163/300 Step: 15/15
total_loss          0.6499
encoder_mse         0.0009
decoder_mse         0.4328
ber_loss            0.4328
----------------------------------------
Epoch 163 training duration 9.99 sec
----------------------------------------
Running validation for epoch 163/300
total_loss          0.7538
encoder_mse         0.0011
decoder_mse         0.5020
ber_loss            0.5020
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-163.pyt
Saving checkpoint done.

Starting epoch 164/300
Batch size = 32
Steps in epoch = 15
Epoch: 164/300 Step: 10/15
total_loss          0.5967
encoder_mse         0.0009
decoder_mse         0.3974
ber_loss            0.3974
----------------------------------------
Epoch: 164/300 Step: 15/15
total_loss          0.6478
encoder_mse         0.0009
decoder_mse         0.4314
ber_loss            0.4314
----------------------------------------
Epoch 164 training duration 10.64 sec
----------------------------------------
Running validation for epoch 164/300
total_loss          0.6549
encoder_mse         0.0011
decoder_mse         0.4361
ber_loss            0.4361
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-164.pyt
Saving checkpoint done.

Starting epoch 165/300
Batch size = 32
Steps in epoch = 15
Epoch: 165/300 Step: 10/15
total_loss          0.6017
encoder_mse         0.0010
decoder_mse         0.4006
ber_loss            0.4006
----------------------------------------
Epoch: 165/300 Step: 15/15
total_loss          0.6039
encoder_mse         0.0010
decoder_mse         0.4021
ber_loss            0.4021
----------------------------------------
Epoch 165 training duration 10.06 sec
----------------------------------------
Running validation for epoch 165/300
total_loss          0.6606
encoder_mse         0.0011
decoder_mse         0.4399
ber_loss            0.4399
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-165.pyt
Saving checkpoint done.

Starting epoch 166/300
Batch size = 32
Steps in epoch = 15
Epoch: 166/300 Step: 10/15
total_loss          0.6781
encoder_mse         0.0009
decoder_mse         0.4516
ber_loss            0.4516
----------------------------------------
Epoch: 166/300 Step: 15/15
total_loss          0.7023
encoder_mse         0.0010
decoder_mse         0.4678
ber_loss            0.4678
----------------------------------------
Epoch 166 training duration 10.03 sec
----------------------------------------
Running validation for epoch 166/300
total_loss          0.4718
encoder_mse         0.0011
decoder_mse         0.3140
ber_loss            0.3140
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-166.pyt
Saving checkpoint done.

Starting epoch 167/300
Batch size = 32
Steps in epoch = 15
Epoch: 167/300 Step: 10/15
total_loss          0.5247
encoder_mse         0.0009
decoder_mse         0.3493
ber_loss            0.3493
----------------------------------------
Epoch: 167/300 Step: 15/15
total_loss          0.5506
encoder_mse         0.0009
decoder_mse         0.3666
ber_loss            0.3666
----------------------------------------
Epoch 167 training duration 10.36 sec
----------------------------------------
Running validation for epoch 167/300
total_loss          0.5552
encoder_mse         0.0011
decoder_mse         0.3696
ber_loss            0.3696
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-167.pyt
Saving checkpoint done.

Starting epoch 168/300
Batch size = 32
Steps in epoch = 15
Epoch: 168/300 Step: 10/15
total_loss          0.5964
encoder_mse         0.0009
decoder_mse         0.3972
ber_loss            0.3972
----------------------------------------
Epoch: 168/300 Step: 15/15
total_loss          0.5965
encoder_mse         0.0009
decoder_mse         0.3973
ber_loss            0.3973
----------------------------------------
Epoch 168 training duration 10.64 sec
----------------------------------------
Running validation for epoch 168/300
total_loss          0.6587
encoder_mse         0.0011
decoder_mse         0.4386
ber_loss            0.4386
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-168.pyt
Saving checkpoint done.

Starting epoch 169/300
Batch size = 32
Steps in epoch = 15
Epoch: 169/300 Step: 10/15
total_loss          0.6785
encoder_mse         0.0009
decoder_mse         0.4519
ber_loss            0.4519
----------------------------------------
Epoch: 169/300 Step: 15/15
total_loss          0.6022
encoder_mse         0.0010
decoder_mse         0.4010
ber_loss            0.4010
----------------------------------------
Epoch 169 training duration 10.22 sec
----------------------------------------
Running validation for epoch 169/300
total_loss          0.4723
encoder_mse         0.0011
decoder_mse         0.3144
ber_loss            0.3144
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-169.pyt
Saving checkpoint done.

Starting epoch 170/300
Batch size = 32
Steps in epoch = 15
Epoch: 170/300 Step: 10/15
total_loss          0.6061
encoder_mse         0.0009
decoder_mse         0.4037
ber_loss            0.4037
----------------------------------------
Epoch: 170/300 Step: 15/15
total_loss          0.6557
encoder_mse         0.0009
decoder_mse         0.4367
ber_loss            0.4367
----------------------------------------
Epoch 170 training duration 9.72 sec
----------------------------------------
Running validation for epoch 170/300
total_loss          0.4662
encoder_mse         0.0011
decoder_mse         0.3103
ber_loss            0.3103
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-170.pyt
Saving checkpoint done.

Starting epoch 171/300
Batch size = 32
Steps in epoch = 15
Epoch: 171/300 Step: 10/15
total_loss          0.5295
encoder_mse         0.0009
decoder_mse         0.3526
ber_loss            0.3526
----------------------------------------
Epoch: 171/300 Step: 15/15
total_loss          0.5528
encoder_mse         0.0009
decoder_mse         0.3681
ber_loss            0.3681
----------------------------------------
Epoch 171 training duration 10.14 sec
----------------------------------------
Running validation for epoch 171/300
total_loss          0.7501
encoder_mse         0.0011
decoder_mse         0.4995
ber_loss            0.4995
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-171.pyt
Saving checkpoint done.

Starting epoch 172/300
Batch size = 32
Steps in epoch = 15
Epoch: 172/300 Step: 10/15
total_loss          0.5967
encoder_mse         0.0009
decoder_mse         0.3973
ber_loss            0.3973
----------------------------------------
Epoch: 172/300 Step: 15/15
total_loss          0.5984
encoder_mse         0.0010
decoder_mse         0.3985
ber_loss            0.3985
----------------------------------------
Epoch 172 training duration 9.94 sec
----------------------------------------
Running validation for epoch 172/300
total_loss          0.3778
encoder_mse         0.0011
decoder_mse         0.2513
ber_loss            0.2513
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-172.pyt
Saving checkpoint done.

Starting epoch 173/300
Batch size = 32
Steps in epoch = 15
Epoch: 173/300 Step: 10/15
total_loss          0.5301
encoder_mse         0.0009
decoder_mse         0.3530
ber_loss            0.3530
----------------------------------------
Epoch: 173/300 Step: 15/15
total_loss          0.5554
encoder_mse         0.0009
decoder_mse         0.3698
ber_loss            0.3698
----------------------------------------
Epoch 173 training duration 10.03 sec
----------------------------------------
Running validation for epoch 173/300
total_loss          0.6569
encoder_mse         0.0011
decoder_mse         0.4374
ber_loss            0.4374
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-173.pyt
Saving checkpoint done.

Starting epoch 174/300
Batch size = 32
Steps in epoch = 15
Epoch: 174/300 Step: 10/15
total_loss          0.6789
encoder_mse         0.0009
decoder_mse         0.4521
ber_loss            0.4521
----------------------------------------
Epoch: 174/300 Step: 15/15
total_loss          0.6515
encoder_mse         0.0009
decoder_mse         0.4339
ber_loss            0.4339
----------------------------------------
Epoch 174 training duration 10.23 sec
----------------------------------------
Running validation for epoch 174/300
total_loss          0.5650
encoder_mse         0.0011
decoder_mse         0.3761
ber_loss            0.3761
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-174.pyt
Saving checkpoint done.

Starting epoch 175/300
Batch size = 32
Steps in epoch = 15
Epoch: 175/300 Step: 10/15
total_loss          0.3748
encoder_mse         0.0010
decoder_mse         0.2494
ber_loss            0.2494
----------------------------------------
Epoch: 175/300 Step: 15/15
total_loss          0.4478
encoder_mse         0.0010
decoder_mse         0.2981
ber_loss            0.2981
----------------------------------------
Epoch 175 training duration 10.32 sec
----------------------------------------
Running validation for epoch 175/300
total_loss          0.5642
encoder_mse         0.0011
decoder_mse         0.3756
ber_loss            0.3756
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-175.pyt
Saving checkpoint done.

Starting epoch 176/300
Batch size = 32
Steps in epoch = 15
Epoch: 176/300 Step: 10/15
total_loss          0.5239
encoder_mse         0.0009
decoder_mse         0.3488
ber_loss            0.3488
----------------------------------------
Epoch: 176/300 Step: 15/15
total_loss          0.6019
encoder_mse         0.0009
decoder_mse         0.4008
ber_loss            0.4008
----------------------------------------
Epoch 176 training duration 10.09 sec
----------------------------------------
Running validation for epoch 176/300
total_loss          0.7445
encoder_mse         0.0011
decoder_mse         0.4958
ber_loss            0.4958
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-176.pyt
Saving checkpoint done.

Starting epoch 177/300
Batch size = 32
Steps in epoch = 15
Epoch: 177/300 Step: 10/15
total_loss          0.5276
encoder_mse         0.0009
decoder_mse         0.3513
ber_loss            0.3513
----------------------------------------
Epoch: 177/300 Step: 15/15
total_loss          0.5036
encoder_mse         0.0009
decoder_mse         0.3353
ber_loss            0.3353
----------------------------------------
Epoch 177 training duration 9.56 sec
----------------------------------------
Running validation for epoch 177/300
total_loss          0.4683
encoder_mse         0.0011
decoder_mse         0.3117
ber_loss            0.3117
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-177.pyt
Saving checkpoint done.

Starting epoch 178/300
Batch size = 32
Steps in epoch = 15
Epoch: 178/300 Step: 10/15
total_loss          0.6077
encoder_mse         0.0009
decoder_mse         0.4047
ber_loss            0.4047
----------------------------------------
Epoch: 178/300 Step: 15/15
total_loss          0.5554
encoder_mse         0.0009
decoder_mse         0.3698
ber_loss            0.3698
----------------------------------------
Epoch 178 training duration 9.85 sec
----------------------------------------
Running validation for epoch 178/300
total_loss          0.4724
encoder_mse         0.0011
decoder_mse         0.3144
ber_loss            0.3144
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-178.pyt
Saving checkpoint done.

Starting epoch 179/300
Batch size = 32
Steps in epoch = 15
Epoch: 179/300 Step: 10/15
total_loss          0.6684
encoder_mse         0.0009
decoder_mse         0.4451
ber_loss            0.4451
----------------------------------------
Epoch: 179/300 Step: 15/15
total_loss          0.6459
encoder_mse         0.0009
decoder_mse         0.4302
ber_loss            0.4302
----------------------------------------
Epoch 179 training duration 10.27 sec
----------------------------------------
Running validation for epoch 179/300
total_loss          0.5686
encoder_mse         0.0011
decoder_mse         0.3785
ber_loss            0.3785
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-179.pyt
Saving checkpoint done.

Starting epoch 180/300
Batch size = 32
Steps in epoch = 15
Epoch: 180/300 Step: 10/15
total_loss          0.5974
encoder_mse         0.0009
decoder_mse         0.3979
ber_loss            0.3979
----------------------------------------
Epoch: 180/300 Step: 15/15
total_loss          0.6484
encoder_mse         0.0009
decoder_mse         0.4318
ber_loss            0.4318
----------------------------------------
Epoch 180 training duration 10.44 sec
----------------------------------------
Running validation for epoch 180/300
total_loss          0.6585
encoder_mse         0.0011
decoder_mse         0.4385
ber_loss            0.4385
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-180.pyt
Saving checkpoint done.

Starting epoch 181/300
Batch size = 32
Steps in epoch = 15
Epoch: 181/300 Step: 10/15
total_loss          0.7631
encoder_mse         0.0009
decoder_mse         0.5083
ber_loss            0.5083
----------------------------------------
Epoch: 181/300 Step: 15/15
total_loss          0.6582
encoder_mse         0.0009
decoder_mse         0.4383
ber_loss            0.4383
----------------------------------------
Epoch 181 training duration 10.52 sec
----------------------------------------
Running validation for epoch 181/300
total_loss          0.5599
encoder_mse         0.0011
decoder_mse         0.3727
ber_loss            0.3727
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-181.pyt
Saving checkpoint done.

Starting epoch 182/300
Batch size = 32
Steps in epoch = 15
Epoch: 182/300 Step: 10/15
total_loss          0.6019
encoder_mse         0.0009
decoder_mse         0.4009
ber_loss            0.4009
----------------------------------------
Epoch: 182/300 Step: 15/15
total_loss          0.6510
encoder_mse         0.0009
decoder_mse         0.4336
ber_loss            0.4336
----------------------------------------
Epoch 182 training duration 9.92 sec
----------------------------------------
Running validation for epoch 182/300
total_loss          0.7520
encoder_mse         0.0011
decoder_mse         0.5008
ber_loss            0.5008
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-182.pyt
Saving checkpoint done.

Starting epoch 183/300
Batch size = 32
Steps in epoch = 15
Epoch: 183/300 Step: 10/15
total_loss          0.6062
encoder_mse         0.0010
decoder_mse         0.4037
ber_loss            0.4037
----------------------------------------
Epoch: 183/300 Step: 15/15
total_loss          0.6028
encoder_mse         0.0010
decoder_mse         0.4014
ber_loss            0.4014
----------------------------------------
Epoch 183 training duration 10.49 sec
----------------------------------------
Running validation for epoch 183/300
total_loss          0.5710
encoder_mse         0.0011
decoder_mse         0.3801
ber_loss            0.3801
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-183.pyt
Saving checkpoint done.

Starting epoch 184/300
Batch size = 32
Steps in epoch = 15
Epoch: 184/300 Step: 10/15
total_loss          0.6688
encoder_mse         0.0009
decoder_mse         0.4455
ber_loss            0.4455
----------------------------------------
Epoch: 184/300 Step: 15/15
total_loss          0.6940
encoder_mse         0.0009
decoder_mse         0.4622
ber_loss            0.4622
----------------------------------------
Epoch 184 training duration 10.24 sec
----------------------------------------
Running validation for epoch 184/300
total_loss          0.7480
encoder_mse         0.0011
decoder_mse         0.4981
ber_loss            0.4981
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-184.pyt
Saving checkpoint done.

Starting epoch 185/300
Batch size = 32
Steps in epoch = 15
Epoch: 185/300 Step: 10/15
total_loss          0.6759
encoder_mse         0.0009
decoder_mse         0.4501
ber_loss            0.4501
----------------------------------------
Epoch: 185/300 Step: 15/15
total_loss          0.6528
encoder_mse         0.0010
decoder_mse         0.4348
ber_loss            0.4348
----------------------------------------
Epoch 185 training duration 10.10 sec
----------------------------------------
Running validation for epoch 185/300
total_loss          0.7541
encoder_mse         0.0011
decoder_mse         0.5022
ber_loss            0.5022
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-185.pyt
Saving checkpoint done.

Starting epoch 186/300
Batch size = 32
Steps in epoch = 15
Epoch: 186/300 Step: 10/15
total_loss          0.4491
encoder_mse         0.0009
decoder_mse         0.2990
ber_loss            0.2990
----------------------------------------
Epoch: 186/300 Step: 15/15
total_loss          0.5014
encoder_mse         0.0009
decoder_mse         0.3338
ber_loss            0.3338
----------------------------------------
Epoch 186 training duration 10.05 sec
----------------------------------------
Running validation for epoch 186/300
total_loss          0.7571
encoder_mse         0.0011
decoder_mse         0.5042
ber_loss            0.5042
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-186.pyt
Saving checkpoint done.

Starting epoch 187/300
Batch size = 32
Steps in epoch = 15
Epoch: 187/300 Step: 10/15
total_loss          0.4526
encoder_mse         0.0009
decoder_mse         0.3013
ber_loss            0.3013
----------------------------------------
Epoch: 187/300 Step: 15/15
total_loss          0.5498
encoder_mse         0.0009
decoder_mse         0.3661
ber_loss            0.3661
----------------------------------------
Epoch 187 training duration 10.19 sec
----------------------------------------
Running validation for epoch 187/300
total_loss          0.5656
encoder_mse         0.0011
decoder_mse         0.3765
ber_loss            0.3765
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-187.pyt
Saving checkpoint done.

Starting epoch 188/300
Batch size = 32
Steps in epoch = 15
Epoch: 188/300 Step: 10/15
total_loss          0.5182
encoder_mse         0.0009
decoder_mse         0.3450
ber_loss            0.3450
----------------------------------------
Epoch: 188/300 Step: 15/15
total_loss          0.5469
encoder_mse         0.0010
decoder_mse         0.3641
ber_loss            0.3641
----------------------------------------
Epoch 188 training duration 10.29 sec
----------------------------------------
Running validation for epoch 188/300
total_loss          0.4709
encoder_mse         0.0011
decoder_mse         0.3134
ber_loss            0.3134
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-188.pyt
Saving checkpoint done.

Starting epoch 189/300
Batch size = 32
Steps in epoch = 15
Epoch: 189/300 Step: 10/15
total_loss          0.6749
encoder_mse         0.0010
decoder_mse         0.4495
ber_loss            0.4495
----------------------------------------
Epoch: 189/300 Step: 15/15
total_loss          0.7039
encoder_mse         0.0009
decoder_mse         0.4688
ber_loss            0.4688
----------------------------------------
Epoch 189 training duration 9.96 sec
----------------------------------------
Running validation for epoch 189/300
total_loss          0.4652
encoder_mse         0.0011
decoder_mse         0.3096
ber_loss            0.3096
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-189.pyt
Saving checkpoint done.

Starting epoch 190/300
Batch size = 32
Steps in epoch = 15
Epoch: 190/300 Step: 10/15
total_loss          0.6765
encoder_mse         0.0009
decoder_mse         0.4506
ber_loss            0.4506
----------------------------------------
Epoch: 190/300 Step: 15/15
total_loss          0.5509
encoder_mse         0.0009
decoder_mse         0.3668
ber_loss            0.3668
----------------------------------------
Epoch 190 training duration 9.75 sec
----------------------------------------
Running validation for epoch 190/300
total_loss          0.6631
encoder_mse         0.0011
decoder_mse         0.4416
ber_loss            0.4416
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-190.pyt
Saving checkpoint done.

Starting epoch 191/300
Batch size = 32
Steps in epoch = 15
Epoch: 191/300 Step: 10/15
total_loss          0.5990
encoder_mse         0.0009
decoder_mse         0.3989
ber_loss            0.3989
----------------------------------------
Epoch: 191/300 Step: 15/15
total_loss          0.5000
encoder_mse         0.0009
decoder_mse         0.3329
ber_loss            0.3329
----------------------------------------
Epoch 191 training duration 10.13 sec
----------------------------------------
Running validation for epoch 191/300
total_loss          0.5730
encoder_mse         0.0011
decoder_mse         0.3815
ber_loss            0.3815
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-191.pyt
Saving checkpoint done.

Starting epoch 192/300
Batch size = 32
Steps in epoch = 15
Epoch: 192/300 Step: 10/15
total_loss          0.3754
encoder_mse         0.0009
decoder_mse         0.2498
ber_loss            0.2498
----------------------------------------
Epoch: 192/300 Step: 15/15
total_loss          0.4987
encoder_mse         0.0009
decoder_mse         0.3320
ber_loss            0.3320
----------------------------------------
Epoch 192 training duration 10.26 sec
----------------------------------------
Running validation for epoch 192/300
total_loss          0.6524
encoder_mse         0.0011
decoder_mse         0.4344
ber_loss            0.4344
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-192.pyt
Saving checkpoint done.

Starting epoch 193/300
Batch size = 32
Steps in epoch = 15
Epoch: 193/300 Step: 10/15
total_loss          0.6860
encoder_mse         0.0009
decoder_mse         0.4569
ber_loss            0.4569
----------------------------------------
Epoch: 193/300 Step: 15/15
total_loss          0.7059
encoder_mse         0.0009
decoder_mse         0.4702
ber_loss            0.4702
----------------------------------------
Epoch 193 training duration 9.59 sec
----------------------------------------
Running validation for epoch 193/300
total_loss          0.6590
encoder_mse         0.0011
decoder_mse         0.4388
ber_loss            0.4388
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-193.pyt
Saving checkpoint done.

Starting epoch 194/300
Batch size = 32
Steps in epoch = 15
Epoch: 194/300 Step: 10/15
total_loss          0.6765
encoder_mse         0.0009
decoder_mse         0.4506
ber_loss            0.4506
----------------------------------------
Epoch: 194/300 Step: 15/15
total_loss          0.6523
encoder_mse         0.0009
decoder_mse         0.4345
ber_loss            0.4345
----------------------------------------
Epoch 194 training duration 10.06 sec
----------------------------------------
Running validation for epoch 194/300
total_loss          0.5709
encoder_mse         0.0011
decoder_mse         0.3801
ber_loss            0.3801
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-194.pyt
Saving checkpoint done.

Starting epoch 195/300
Batch size = 32
Steps in epoch = 15
Epoch: 195/300 Step: 10/15
total_loss          0.5312
encoder_mse         0.0009
decoder_mse         0.3537
ber_loss            0.3537
----------------------------------------
Epoch: 195/300 Step: 15/15
total_loss          0.5560
encoder_mse         0.0010
decoder_mse         0.3702
ber_loss            0.3702
----------------------------------------
Epoch 195 training duration 9.95 sec
----------------------------------------
Running validation for epoch 195/300
total_loss          0.6581
encoder_mse         0.0011
decoder_mse         0.4382
ber_loss            0.4382
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-195.pyt
Saving checkpoint done.

Starting epoch 196/300
Batch size = 32
Steps in epoch = 15
Epoch: 196/300 Step: 10/15
total_loss          0.3024
encoder_mse         0.0010
decoder_mse         0.2011
ber_loss            0.2011
----------------------------------------
Epoch: 196/300 Step: 15/15
total_loss          0.3523
encoder_mse         0.0010
decoder_mse         0.2344
ber_loss            0.2344
----------------------------------------
Epoch 196 training duration 9.99 sec
----------------------------------------
Running validation for epoch 196/300
total_loss          0.6587
encoder_mse         0.0011
decoder_mse         0.4386
ber_loss            0.4386
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-196.pyt
Saving checkpoint done.

Starting epoch 197/300
Batch size = 32
Steps in epoch = 15
Epoch: 197/300 Step: 10/15
total_loss          0.6762
encoder_mse         0.0009
decoder_mse         0.4504
ber_loss            0.4504
----------------------------------------
Epoch: 197/300 Step: 15/15
total_loss          0.6496
encoder_mse         0.0009
decoder_mse         0.4326
ber_loss            0.4326
----------------------------------------
Epoch 197 training duration 10.18 sec
----------------------------------------
Running validation for epoch 197/300
total_loss          0.6643
encoder_mse         0.0011
decoder_mse         0.4424
ber_loss            0.4424
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-197.pyt
Saving checkpoint done.

Starting epoch 198/300
Batch size = 32
Steps in epoch = 15
Epoch: 198/300 Step: 10/15
total_loss          0.7463
encoder_mse         0.0010
decoder_mse         0.4971
ber_loss            0.4971
----------------------------------------
Epoch: 198/300 Step: 15/15
total_loss          0.7497
encoder_mse         0.0010
decoder_mse         0.4994
ber_loss            0.4994
----------------------------------------
Epoch 198 training duration 10.44 sec
----------------------------------------
Running validation for epoch 198/300
total_loss          0.5653
encoder_mse         0.0011
decoder_mse         0.3764
ber_loss            0.3764
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-198.pyt
Saving checkpoint done.

Starting epoch 199/300
Batch size = 32
Steps in epoch = 15
Epoch: 199/300 Step: 10/15
total_loss          0.7499
encoder_mse         0.0010
decoder_mse         0.4995
ber_loss            0.4995
----------------------------------------
Epoch: 199/300 Step: 15/15
total_loss          0.7526
encoder_mse         0.0010
decoder_mse         0.5013
ber_loss            0.5013
----------------------------------------
Epoch 199 training duration 10.01 sec
----------------------------------------
Running validation for epoch 199/300
total_loss          0.7466
encoder_mse         0.0011
decoder_mse         0.4972
ber_loss            0.4972
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-199.pyt
Saving checkpoint done.

Starting epoch 200/300
Batch size = 32
Steps in epoch = 15
Epoch: 200/300 Step: 10/15
total_loss          0.7515
encoder_mse         0.0010
decoder_mse         0.5006
ber_loss            0.5006
----------------------------------------
Epoch: 200/300 Step: 15/15
total_loss          0.7507
encoder_mse         0.0010
decoder_mse         0.5000
ber_loss            0.5000
----------------------------------------
Epoch 200 training duration 9.89 sec
----------------------------------------
Running validation for epoch 200/300
total_loss          0.7601
encoder_mse         0.0011
decoder_mse         0.5062
ber_loss            0.5062
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-200.pyt
Saving checkpoint done.

Starting epoch 201/300
Batch size = 32
Steps in epoch = 15
Epoch: 201/300 Step: 10/15
total_loss          0.6774
encoder_mse         0.0010
decoder_mse         0.4512
ber_loss            0.4512
----------------------------------------
Epoch: 201/300 Step: 15/15
total_loss          0.6525
encoder_mse         0.0010
decoder_mse         0.4346
ber_loss            0.4346
----------------------------------------
Epoch 201 training duration 9.93 sec
----------------------------------------
Running validation for epoch 201/300
total_loss          0.3756
encoder_mse         0.0011
decoder_mse         0.2499
ber_loss            0.2499
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-201.pyt
Saving checkpoint done.

Starting epoch 202/300
Batch size = 32
Steps in epoch = 15
Epoch: 202/300 Step: 10/15
total_loss          0.5319
encoder_mse         0.0009
decoder_mse         0.3542
ber_loss            0.3542
----------------------------------------
Epoch: 202/300 Step: 15/15
total_loss          0.5061
encoder_mse         0.0009
decoder_mse         0.3370
ber_loss            0.3370
----------------------------------------
Epoch 202 training duration 10.42 sec
----------------------------------------
Running validation for epoch 202/300
total_loss          0.7497
encoder_mse         0.0011
decoder_mse         0.4993
ber_loss            0.4993
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-202.pyt
Saving checkpoint done.

Starting epoch 203/300
Batch size = 32
Steps in epoch = 15
Epoch: 203/300 Step: 10/15
total_loss          0.7510
encoder_mse         0.0009
decoder_mse         0.5003
ber_loss            0.5003
----------------------------------------
Epoch: 203/300 Step: 15/15
total_loss          0.6524
encoder_mse         0.0009
decoder_mse         0.4345
ber_loss            0.4345
----------------------------------------
Epoch 203 training duration 9.79 sec
----------------------------------------
Running validation for epoch 203/300
total_loss          0.6529
encoder_mse         0.0011
decoder_mse         0.4348
ber_loss            0.4348
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-203.pyt
Saving checkpoint done.

Starting epoch 204/300
Batch size = 32
Steps in epoch = 15
Epoch: 204/300 Step: 10/15
total_loss          0.6004
encoder_mse         0.0009
decoder_mse         0.3998
ber_loss            0.3998
----------------------------------------
Epoch: 204/300 Step: 15/15
total_loss          0.5998
encoder_mse         0.0009
decoder_mse         0.3994
ber_loss            0.3994
----------------------------------------
Epoch 204 training duration 10.08 sec
----------------------------------------
Running validation for epoch 204/300
total_loss          0.6580
encoder_mse         0.0011
decoder_mse         0.4381
ber_loss            0.4381
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-204.pyt
Saving checkpoint done.

Starting epoch 205/300
Batch size = 32
Steps in epoch = 15
Epoch: 205/300 Step: 10/15
total_loss          0.6023
encoder_mse         0.0009
decoder_mse         0.4011
ber_loss            0.4011
----------------------------------------
Epoch: 205/300 Step: 15/15
total_loss          0.6509
encoder_mse         0.0009
decoder_mse         0.4335
ber_loss            0.4335
----------------------------------------
Epoch 205 training duration 9.60 sec
----------------------------------------
Running validation for epoch 205/300
total_loss          0.6558
encoder_mse         0.0011
decoder_mse         0.4367
ber_loss            0.4367
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-205.pyt
Saving checkpoint done.

Starting epoch 206/300
Batch size = 32
Steps in epoch = 15
Epoch: 206/300 Step: 10/15
total_loss          0.6770
encoder_mse         0.0009
decoder_mse         0.4509
ber_loss            0.4509
----------------------------------------
Epoch: 206/300 Step: 15/15
total_loss          0.7043
encoder_mse         0.0009
decoder_mse         0.4691
ber_loss            0.4691
----------------------------------------
Epoch 206 training duration 10.52 sec
----------------------------------------
Running validation for epoch 206/300
total_loss          0.5645
encoder_mse         0.0011
decoder_mse         0.3758
ber_loss            0.3758
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-206.pyt
Saving checkpoint done.

Starting epoch 207/300
Batch size = 32
Steps in epoch = 15
Epoch: 207/300 Step: 10/15
total_loss          0.5276
encoder_mse         0.0010
decoder_mse         0.3513
ber_loss            0.3513
----------------------------------------
Epoch: 207/300 Step: 15/15
total_loss          0.5999
encoder_mse         0.0009
decoder_mse         0.3995
ber_loss            0.3995
----------------------------------------
Epoch 207 training duration 10.40 sec
----------------------------------------
Running validation for epoch 207/300
total_loss          0.1890
encoder_mse         0.0011
decoder_mse         0.1255
ber_loss            0.1255
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-207.pyt
Saving checkpoint done.

Starting epoch 208/300
Batch size = 32
Steps in epoch = 15
Epoch: 208/300 Step: 10/15
total_loss          0.5981
encoder_mse         0.0009
decoder_mse         0.3983
ber_loss            0.3983
----------------------------------------
Epoch: 208/300 Step: 15/15
total_loss          0.6471
encoder_mse         0.0009
decoder_mse         0.4310
ber_loss            0.4310
----------------------------------------
Epoch 208 training duration 9.77 sec
----------------------------------------
Running validation for epoch 208/300
total_loss          0.6645
encoder_mse         0.0011
decoder_mse         0.4425
ber_loss            0.4425
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-208.pyt
Saving checkpoint done.

Starting epoch 209/300
Batch size = 32
Steps in epoch = 15
Epoch: 209/300 Step: 10/15
total_loss          0.7526
encoder_mse         0.0009
decoder_mse         0.5013
ber_loss            0.5013
----------------------------------------
Epoch: 209/300 Step: 15/15
total_loss          0.6512
encoder_mse         0.0009
decoder_mse         0.4337
ber_loss            0.4337
----------------------------------------
Epoch 209 training duration 9.70 sec
----------------------------------------
Running validation for epoch 209/300
total_loss          0.6539
encoder_mse         0.0011
decoder_mse         0.4354
ber_loss            0.4354
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-209.pyt
Saving checkpoint done.

Starting epoch 210/300
Batch size = 32
Steps in epoch = 15
Epoch: 210/300 Step: 10/15
total_loss          0.5966
encoder_mse         0.0010
decoder_mse         0.3973
ber_loss            0.3973
----------------------------------------
Epoch: 210/300 Step: 15/15
total_loss          0.5983
encoder_mse         0.0010
decoder_mse         0.3984
ber_loss            0.3984
----------------------------------------
Epoch 210 training duration 10.29 sec
----------------------------------------
Running validation for epoch 210/300
total_loss          0.5704
encoder_mse         0.0011
decoder_mse         0.3798
ber_loss            0.3798
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-210.pyt
Saving checkpoint done.

Starting epoch 211/300
Batch size = 32
Steps in epoch = 15
Epoch: 211/300 Step: 10/15
total_loss          0.6755
encoder_mse         0.0010
decoder_mse         0.4499
ber_loss            0.4499
----------------------------------------
Epoch: 211/300 Step: 15/15
total_loss          0.6538
encoder_mse         0.0010
decoder_mse         0.4354
ber_loss            0.4354
----------------------------------------
Epoch 211 training duration 10.17 sec
----------------------------------------
Running validation for epoch 211/300
total_loss          0.6555
encoder_mse         0.0011
decoder_mse         0.4365
ber_loss            0.4365
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-211.pyt
Saving checkpoint done.

Starting epoch 212/300
Batch size = 32
Steps in epoch = 15
Epoch: 212/300 Step: 10/15
total_loss          0.6778
encoder_mse         0.0009
decoder_mse         0.4514
ber_loss            0.4514
----------------------------------------
Epoch: 212/300 Step: 15/15
total_loss          0.5525
encoder_mse         0.0009
decoder_mse         0.3679
ber_loss            0.3679
----------------------------------------
Epoch 212 training duration 10.02 sec
----------------------------------------
Running validation for epoch 212/300
total_loss          0.6600
encoder_mse         0.0011
decoder_mse         0.4395
ber_loss            0.4395
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-212.pyt
Saving checkpoint done.

Starting epoch 213/300
Batch size = 32
Steps in epoch = 15
Epoch: 213/300 Step: 10/15
total_loss          0.6061
encoder_mse         0.0009
decoder_mse         0.4037
ber_loss            0.4037
----------------------------------------
Epoch: 213/300 Step: 15/15
total_loss          0.5557
encoder_mse         0.0009
decoder_mse         0.3700
ber_loss            0.3700
----------------------------------------
Epoch 213 training duration 10.34 sec
----------------------------------------
Running validation for epoch 213/300
total_loss          0.5659
encoder_mse         0.0011
decoder_mse         0.3767
ber_loss            0.3767
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-213.pyt
Saving checkpoint done.

Starting epoch 214/300
Batch size = 32
Steps in epoch = 15
Epoch: 214/300 Step: 10/15
total_loss          0.5972
encoder_mse         0.0010
decoder_mse         0.3977
ber_loss            0.3977
----------------------------------------
Epoch: 214/300 Step: 15/15
total_loss          0.6020
encoder_mse         0.0010
decoder_mse         0.4009
ber_loss            0.4009
----------------------------------------
Epoch 214 training duration 10.15 sec
----------------------------------------
Running validation for epoch 214/300
total_loss          0.5670
encoder_mse         0.0011
decoder_mse         0.3775
ber_loss            0.3775
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-214.pyt
Saving checkpoint done.

Starting epoch 215/300
Batch size = 32
Steps in epoch = 15
Epoch: 215/300 Step: 10/15
total_loss          0.5224
encoder_mse         0.0009
decoder_mse         0.3479
ber_loss            0.3479
----------------------------------------
Epoch: 215/300 Step: 15/15
total_loss          0.5473
encoder_mse         0.0010
decoder_mse         0.3644
ber_loss            0.3644
----------------------------------------
Epoch 215 training duration 10.32 sec
----------------------------------------
Running validation for epoch 215/300
total_loss          0.5625
encoder_mse         0.0011
decoder_mse         0.3745
ber_loss            0.3745
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-215.pyt
Saving checkpoint done.

Starting epoch 216/300
Batch size = 32
Steps in epoch = 15
Epoch: 216/300 Step: 10/15
total_loss          0.6001
encoder_mse         0.0009
decoder_mse         0.3996
ber_loss            0.3996
----------------------------------------
Epoch: 216/300 Step: 15/15
total_loss          0.4994
encoder_mse         0.0009
decoder_mse         0.3325
ber_loss            0.3325
----------------------------------------
Epoch 216 training duration 10.67 sec
----------------------------------------
Running validation for epoch 216/300
total_loss          0.7541
encoder_mse         0.0011
decoder_mse         0.5022
ber_loss            0.5022
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-216.pyt
Saving checkpoint done.

Starting epoch 217/300
Batch size = 32
Steps in epoch = 15
Epoch: 217/300 Step: 10/15
total_loss          0.6722
encoder_mse         0.0010
decoder_mse         0.4477
ber_loss            0.4477
----------------------------------------
Epoch: 217/300 Step: 15/15
total_loss          0.5969
encoder_mse         0.0010
decoder_mse         0.3975
ber_loss            0.3975
----------------------------------------
Epoch 217 training duration 9.94 sec
----------------------------------------
Running validation for epoch 217/300
total_loss          0.4710
encoder_mse         0.0011
decoder_mse         0.3135
ber_loss            0.3135
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-217.pyt
Saving checkpoint done.

Starting epoch 218/300
Batch size = 32
Steps in epoch = 15
Epoch: 218/300 Step: 10/15
total_loss          0.5276
encoder_mse         0.0010
decoder_mse         0.3512
ber_loss            0.3512
----------------------------------------
Epoch: 218/300 Step: 15/15
total_loss          0.6021
encoder_mse         0.0009
decoder_mse         0.4010
ber_loss            0.4010
----------------------------------------
Epoch 218 training duration 10.18 sec
----------------------------------------
Running validation for epoch 218/300
total_loss          0.3777
encoder_mse         0.0011
decoder_mse         0.2513
ber_loss            0.2513
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-218.pyt
Saving checkpoint done.

Starting epoch 219/300
Batch size = 32
Steps in epoch = 15
Epoch: 219/300 Step: 10/15
total_loss          0.6742
encoder_mse         0.0009
decoder_mse         0.4490
ber_loss            0.4490
----------------------------------------
Epoch: 219/300 Step: 15/15
total_loss          0.7031
encoder_mse         0.0009
decoder_mse         0.4683
ber_loss            0.4683
----------------------------------------
Epoch 219 training duration 10.58 sec
----------------------------------------
Running validation for epoch 219/300
total_loss          0.6547
encoder_mse         0.0011
decoder_mse         0.4360
ber_loss            0.4360
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-219.pyt
Saving checkpoint done.

Starting epoch 220/300
Batch size = 32
Steps in epoch = 15
Epoch: 220/300 Step: 10/15
total_loss          0.7468
encoder_mse         0.0009
decoder_mse         0.4975
ber_loss            0.4975
----------------------------------------
Epoch: 220/300 Step: 15/15
total_loss          0.6460
encoder_mse         0.0009
decoder_mse         0.4302
ber_loss            0.4302
----------------------------------------
Epoch 220 training duration 10.37 sec
----------------------------------------
Running validation for epoch 220/300
total_loss          0.6578
encoder_mse         0.0011
decoder_mse         0.4380
ber_loss            0.4380
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-220.pyt
Saving checkpoint done.

Starting epoch 221/300
Batch size = 32
Steps in epoch = 15
Epoch: 221/300 Step: 10/15
total_loss          0.3742
encoder_mse         0.0009
decoder_mse         0.2490
ber_loss            0.2490
----------------------------------------
Epoch: 221/300 Step: 15/15
total_loss          0.5021
encoder_mse         0.0009
decoder_mse         0.3343
ber_loss            0.3343
----------------------------------------
Epoch 221 training duration 10.09 sec
----------------------------------------
Running validation for epoch 221/300
total_loss          0.5644
encoder_mse         0.0011
decoder_mse         0.3758
ber_loss            0.3758
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-221.pyt
Saving checkpoint done.

Starting epoch 222/300
Batch size = 32
Steps in epoch = 15
Epoch: 222/300 Step: 10/15
total_loss          0.6769
encoder_mse         0.0009
decoder_mse         0.4508
ber_loss            0.4508
----------------------------------------
Epoch: 222/300 Step: 15/15
total_loss          0.6035
encoder_mse         0.0009
decoder_mse         0.4019
ber_loss            0.4019
----------------------------------------
Epoch 222 training duration 10.32 sec
----------------------------------------
Running validation for epoch 222/300
total_loss          0.7472
encoder_mse         0.0011
decoder_mse         0.4976
ber_loss            0.4976
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-222.pyt
Saving checkpoint done.

Starting epoch 223/300
Batch size = 32
Steps in epoch = 15
Epoch: 223/300 Step: 10/15
total_loss          0.5316
encoder_mse         0.0009
decoder_mse         0.3540
ber_loss            0.3540
----------------------------------------
Epoch: 223/300 Step: 15/15
total_loss          0.6025
encoder_mse         0.0010
decoder_mse         0.4012
ber_loss            0.4012
----------------------------------------
Epoch 223 training duration 10.04 sec
----------------------------------------
Running validation for epoch 223/300
total_loss          0.7526
encoder_mse         0.0011
decoder_mse         0.5012
ber_loss            0.5012
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-223.pyt
Saving checkpoint done.

Starting epoch 224/300
Batch size = 32
Steps in epoch = 15
Epoch: 224/300 Step: 10/15
total_loss          0.5239
encoder_mse         0.0009
decoder_mse         0.3488
ber_loss            0.3488
----------------------------------------
Epoch: 224/300 Step: 15/15
total_loss          0.5508
encoder_mse         0.0009
decoder_mse         0.3668
ber_loss            0.3668
----------------------------------------
Epoch 224 training duration 10.24 sec
----------------------------------------
Running validation for epoch 224/300
total_loss          0.5648
encoder_mse         0.0011
decoder_mse         0.3760
ber_loss            0.3760
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-224.pyt
Saving checkpoint done.

Starting epoch 225/300
Batch size = 32
Steps in epoch = 15
Epoch: 225/300 Step: 10/15
total_loss          0.6727
encoder_mse         0.0009
decoder_mse         0.4480
ber_loss            0.4480
----------------------------------------
Epoch: 225/300 Step: 15/15
total_loss          0.6489
encoder_mse         0.0009
decoder_mse         0.4322
ber_loss            0.4322
----------------------------------------
Epoch 225 training duration 10.13 sec
----------------------------------------
Running validation for epoch 225/300
total_loss          0.6504
encoder_mse         0.0011
decoder_mse         0.4331
ber_loss            0.4331
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-225.pyt
Saving checkpoint done.

Starting epoch 226/300
Batch size = 32
Steps in epoch = 15
Epoch: 226/300 Step: 10/15
total_loss          0.6748
encoder_mse         0.0009
decoder_mse         0.4495
ber_loss            0.4495
----------------------------------------
Epoch: 226/300 Step: 15/15
total_loss          0.6997
encoder_mse         0.0009
decoder_mse         0.4661
ber_loss            0.4661
----------------------------------------
Epoch 226 training duration 10.31 sec
----------------------------------------
Running validation for epoch 226/300
total_loss          0.6548
encoder_mse         0.0011
decoder_mse         0.4360
ber_loss            0.4360
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-226.pyt
Saving checkpoint done.

Starting epoch 227/300
Batch size = 32
Steps in epoch = 15
Epoch: 227/300 Step: 10/15
total_loss          0.7517
encoder_mse         0.0010
decoder_mse         0.5007
ber_loss            0.5007
----------------------------------------
Epoch: 227/300 Step: 15/15
total_loss          0.6525
encoder_mse         0.0010
decoder_mse         0.4346
ber_loss            0.4346
----------------------------------------
Epoch 227 training duration 10.43 sec
----------------------------------------
Running validation for epoch 227/300
total_loss          0.4697
encoder_mse         0.0011
decoder_mse         0.3126
ber_loss            0.3126
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-227.pyt
Saving checkpoint done.

Starting epoch 228/300
Batch size = 32
Steps in epoch = 15
Epoch: 228/300 Step: 10/15
total_loss          0.4530
encoder_mse         0.0010
decoder_mse         0.3015
ber_loss            0.3015
----------------------------------------
Epoch: 228/300 Step: 15/15
total_loss          0.4517
encoder_mse         0.0010
decoder_mse         0.3007
ber_loss            0.3007
----------------------------------------
Epoch 228 training duration 10.44 sec
----------------------------------------
Running validation for epoch 228/300
total_loss          0.3754
encoder_mse         0.0011
decoder_mse         0.2497
ber_loss            0.2497
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-228.pyt
Saving checkpoint done.

Starting epoch 229/300
Batch size = 32
Steps in epoch = 15
Epoch: 229/300 Step: 10/15
total_loss          0.5232
encoder_mse         0.0010
decoder_mse         0.3484
ber_loss            0.3484
----------------------------------------
Epoch: 229/300 Step: 15/15
total_loss          0.6001
encoder_mse         0.0010
decoder_mse         0.3996
ber_loss            0.3996
----------------------------------------
Epoch 229 training duration 9.96 sec
----------------------------------------
Running validation for epoch 229/300
total_loss          0.5630
encoder_mse         0.0011
decoder_mse         0.3748
ber_loss            0.3748
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-229.pyt
Saving checkpoint done.

Starting epoch 230/300
Batch size = 32
Steps in epoch = 15
Epoch: 230/300 Step: 10/15
total_loss          0.6017
encoder_mse         0.0009
decoder_mse         0.4007
ber_loss            0.4007
----------------------------------------
Epoch: 230/300 Step: 15/15
total_loss          0.5508
encoder_mse         0.0009
decoder_mse         0.3668
ber_loss            0.3668
----------------------------------------
Epoch 230 training duration 10.33 sec
----------------------------------------
Running validation for epoch 230/300
total_loss          0.6527
encoder_mse         0.0011
decoder_mse         0.4346
ber_loss            0.4346
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-230.pyt
Saving checkpoint done.

Starting epoch 231/300
Batch size = 32
Steps in epoch = 15
Epoch: 231/300 Step: 10/15
total_loss          0.5978
encoder_mse         0.0010
decoder_mse         0.3981
ber_loss            0.3981
----------------------------------------
Epoch: 231/300 Step: 15/15
total_loss          0.5480
encoder_mse         0.0010
decoder_mse         0.3649
ber_loss            0.3649
----------------------------------------
Epoch 231 training duration 10.25 sec
----------------------------------------
Running validation for epoch 231/300
total_loss          0.6621
encoder_mse         0.0011
decoder_mse         0.4409
ber_loss            0.4409
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-231.pyt
Saving checkpoint done.

Starting epoch 232/300
Batch size = 32
Steps in epoch = 15
Epoch: 232/300 Step: 10/15
total_loss          0.5240
encoder_mse         0.0009
decoder_mse         0.3489
ber_loss            0.3489
----------------------------------------
Epoch: 232/300 Step: 15/15
total_loss          0.5997
encoder_mse         0.0009
decoder_mse         0.3993
ber_loss            0.3993
----------------------------------------
Epoch 232 training duration 10.13 sec
----------------------------------------
Running validation for epoch 232/300
total_loss          0.6524
encoder_mse         0.0011
decoder_mse         0.4344
ber_loss            0.4344
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-232.pyt
Saving checkpoint done.

Starting epoch 233/300
Batch size = 32
Steps in epoch = 15
Epoch: 233/300 Step: 10/15
total_loss          0.6721
encoder_mse         0.0009
decoder_mse         0.4476
ber_loss            0.4476
----------------------------------------
Epoch: 233/300 Step: 15/15
total_loss          0.6982
encoder_mse         0.0009
decoder_mse         0.4650
ber_loss            0.4650
----------------------------------------
Epoch 233 training duration 10.38 sec
----------------------------------------
Running validation for epoch 233/300
total_loss          0.4707
encoder_mse         0.0011
decoder_mse         0.3133
ber_loss            0.3133
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-233.pyt
Saving checkpoint done.

Starting epoch 234/300
Batch size = 32
Steps in epoch = 15
Epoch: 234/300 Step: 10/15
total_loss          0.6020
encoder_mse         0.0009
decoder_mse         0.4009
ber_loss            0.4009
----------------------------------------
Epoch: 234/300 Step: 15/15
total_loss          0.6501
encoder_mse         0.0009
decoder_mse         0.4330
ber_loss            0.4330
----------------------------------------
Epoch 234 training duration 9.90 sec
----------------------------------------
Running validation for epoch 234/300
total_loss          0.4686
encoder_mse         0.0011
decoder_mse         0.3119
ber_loss            0.3119
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-234.pyt
Saving checkpoint done.

Starting epoch 235/300
Batch size = 32
Steps in epoch = 15
Epoch: 235/300 Step: 10/15
total_loss          0.7537
encoder_mse         0.0009
decoder_mse         0.5020
ber_loss            0.5020
----------------------------------------
Epoch: 235/300 Step: 15/15
total_loss          0.7522
encoder_mse         0.0009
decoder_mse         0.5011
ber_loss            0.5011
----------------------------------------
Epoch 235 training duration 10.31 sec
----------------------------------------
Running validation for epoch 235/300
total_loss          0.5596
encoder_mse         0.0011
decoder_mse         0.3725
ber_loss            0.3725
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-235.pyt
Saving checkpoint done.

Starting epoch 236/300
Batch size = 32
Steps in epoch = 15
Epoch: 236/300 Step: 10/15
total_loss          0.7541
encoder_mse         0.0010
decoder_mse         0.5022
ber_loss            0.5022
----------------------------------------
Epoch: 236/300 Step: 15/15
total_loss          0.7532
encoder_mse         0.0010
decoder_mse         0.5017
ber_loss            0.5017
----------------------------------------
Epoch 236 training duration 10.02 sec
----------------------------------------
Running validation for epoch 236/300
total_loss          0.7454
encoder_mse         0.0011
decoder_mse         0.4964
ber_loss            0.4964
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-236.pyt
Saving checkpoint done.

Starting epoch 237/300
Batch size = 32
Steps in epoch = 15
Epoch: 237/300 Step: 10/15
total_loss          0.6039
encoder_mse         0.0009
decoder_mse         0.4022
ber_loss            0.4022
----------------------------------------
Epoch: 237/300 Step: 15/15
total_loss          0.6015
encoder_mse         0.0009
decoder_mse         0.4006
ber_loss            0.4006
----------------------------------------
Epoch 237 training duration 10.30 sec
----------------------------------------
Running validation for epoch 237/300
total_loss          0.6543
encoder_mse         0.0011
decoder_mse         0.4357
ber_loss            0.4357
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-237.pyt
Saving checkpoint done.

Starting epoch 238/300
Batch size = 32
Steps in epoch = 15
Epoch: 238/300 Step: 10/15
total_loss          0.7535
encoder_mse         0.0009
decoder_mse         0.5019
ber_loss            0.5019
----------------------------------------
Epoch: 238/300 Step: 15/15
total_loss          0.7531
encoder_mse         0.0009
decoder_mse         0.5016
ber_loss            0.5016
----------------------------------------
Epoch 238 training duration 10.03 sec
----------------------------------------
Running validation for epoch 238/300
total_loss          0.5633
encoder_mse         0.0011
decoder_mse         0.3750
ber_loss            0.3750
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-238.pyt
Saving checkpoint done.

Starting epoch 239/300
Batch size = 32
Steps in epoch = 15
Epoch: 239/300 Step: 10/15
total_loss          0.6732
encoder_mse         0.0009
decoder_mse         0.4484
ber_loss            0.4484
----------------------------------------
Epoch: 239/300 Step: 15/15
total_loss          0.6991
encoder_mse         0.0009
decoder_mse         0.4656
ber_loss            0.4656
----------------------------------------
Epoch 239 training duration 9.98 sec
----------------------------------------
Running validation for epoch 239/300
total_loss          0.4722
encoder_mse         0.0011
decoder_mse         0.3143
ber_loss            0.3143
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-239.pyt
Saving checkpoint done.

Starting epoch 240/300
Batch size = 32
Steps in epoch = 15
Epoch: 240/300 Step: 10/15
total_loss          0.6675
encoder_mse         0.0009
decoder_mse         0.4446
ber_loss            0.4446
----------------------------------------
Epoch: 240/300 Step: 15/15
total_loss          0.5450
encoder_mse         0.0009
decoder_mse         0.3629
ber_loss            0.3629
----------------------------------------
Epoch 240 training duration 10.34 sec
----------------------------------------
Running validation for epoch 240/300
total_loss          0.6545
encoder_mse         0.0011
decoder_mse         0.4358
ber_loss            0.4358
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-240.pyt
Saving checkpoint done.

Starting epoch 241/300
Batch size = 32
Steps in epoch = 15
Epoch: 241/300 Step: 10/15
total_loss          0.4485
encoder_mse         0.0009
decoder_mse         0.2986
ber_loss            0.2986
----------------------------------------
Epoch: 241/300 Step: 15/15
total_loss          0.4453
encoder_mse         0.0009
decoder_mse         0.2965
ber_loss            0.2965
----------------------------------------
Epoch 241 training duration 10.32 sec
----------------------------------------
Running validation for epoch 241/300
total_loss          0.4658
encoder_mse         0.0011
decoder_mse         0.3100
ber_loss            0.3100
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-241.pyt
Saving checkpoint done.

Starting epoch 242/300
Batch size = 32
Steps in epoch = 15
Epoch: 242/300 Step: 10/15
total_loss          0.5947
encoder_mse         0.0009
decoder_mse         0.3960
ber_loss            0.3960
----------------------------------------
Epoch: 242/300 Step: 15/15
total_loss          0.5470
encoder_mse         0.0009
decoder_mse         0.3643
ber_loss            0.3643
----------------------------------------
Epoch 242 training duration 10.39 sec
----------------------------------------
Running validation for epoch 242/300
total_loss          0.6558
encoder_mse         0.0011
decoder_mse         0.4367
ber_loss            0.4367
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-242.pyt
Saving checkpoint done.

Starting epoch 243/300
Batch size = 32
Steps in epoch = 15
Epoch: 243/300 Step: 10/15
total_loss          0.5280
encoder_mse         0.0009
decoder_mse         0.3515
ber_loss            0.3515
----------------------------------------
Epoch: 243/300 Step: 15/15
total_loss          0.5539
encoder_mse         0.0009
decoder_mse         0.3689
ber_loss            0.3689
----------------------------------------
Epoch 243 training duration 9.95 sec
----------------------------------------
Running validation for epoch 243/300
total_loss          0.6535
encoder_mse         0.0011
decoder_mse         0.4352
ber_loss            0.4352
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-243.pyt
Saving checkpoint done.

Starting epoch 244/300
Batch size = 32
Steps in epoch = 15
Epoch: 244/300 Step: 10/15
total_loss          0.6797
encoder_mse         0.0009
decoder_mse         0.4527
ber_loss            0.4527
----------------------------------------
Epoch: 244/300 Step: 15/15
total_loss          0.6528
encoder_mse         0.0009
decoder_mse         0.4348
ber_loss            0.4348
----------------------------------------
Epoch 244 training duration 10.11 sec
----------------------------------------
Running validation for epoch 244/300
total_loss          0.6547
encoder_mse         0.0011
decoder_mse         0.4359
ber_loss            0.4359
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-244.pyt
Saving checkpoint done.

Starting epoch 245/300
Batch size = 32
Steps in epoch = 15
Epoch: 245/300 Step: 10/15
total_loss          0.6030
encoder_mse         0.0010
decoder_mse         0.4015
ber_loss            0.4015
----------------------------------------
Epoch: 245/300 Step: 15/15
total_loss          0.6009
encoder_mse         0.0010
decoder_mse         0.4002
ber_loss            0.4002
----------------------------------------
Epoch 245 training duration 10.52 sec
----------------------------------------
Running validation for epoch 245/300
total_loss          0.4741
encoder_mse         0.0011
decoder_mse         0.3156
ber_loss            0.3156
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-245.pyt
Saving checkpoint done.

Starting epoch 246/300
Batch size = 32
Steps in epoch = 15
Epoch: 246/300 Step: 10/15
total_loss          0.6704
encoder_mse         0.0010
decoder_mse         0.4465
ber_loss            0.4465
----------------------------------------
Epoch: 246/300 Step: 15/15
total_loss          0.6983
encoder_mse         0.0010
decoder_mse         0.4651
ber_loss            0.4651
----------------------------------------
Epoch 246 training duration 10.24 sec
----------------------------------------
Running validation for epoch 246/300
total_loss          0.4744
encoder_mse         0.0011
decoder_mse         0.3157
ber_loss            0.3157
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-246.pyt
Saving checkpoint done.

Starting epoch 247/300
Batch size = 32
Steps in epoch = 15
Epoch: 247/300 Step: 10/15
total_loss          0.6809
encoder_mse         0.0009
decoder_mse         0.4535
ber_loss            0.4535
----------------------------------------
Epoch: 247/300 Step: 15/15
total_loss          0.6003
encoder_mse         0.0009
decoder_mse         0.3998
ber_loss            0.3998
----------------------------------------
Epoch 247 training duration 10.29 sec
----------------------------------------
Running validation for epoch 247/300
total_loss          0.5632
encoder_mse         0.0011
decoder_mse         0.3750
ber_loss            0.3750
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-247.pyt
Saving checkpoint done.

Starting epoch 248/300
Batch size = 32
Steps in epoch = 15
Epoch: 248/300 Step: 10/15
total_loss          0.6759
encoder_mse         0.0009
decoder_mse         0.4502
ber_loss            0.4502
----------------------------------------
Epoch: 248/300 Step: 15/15
total_loss          0.5525
encoder_mse         0.0010
decoder_mse         0.3679
ber_loss            0.3679
----------------------------------------
Epoch 248 training duration 10.58 sec
----------------------------------------
Running validation for epoch 248/300
total_loss          0.7454
encoder_mse         0.0011
decoder_mse         0.4964
ber_loss            0.4964
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-248.pyt
Saving checkpoint done.

Starting epoch 249/300
Batch size = 32
Steps in epoch = 15
Epoch: 249/300 Step: 10/15
total_loss          0.6025
encoder_mse         0.0009
decoder_mse         0.4012
ber_loss            0.4012
----------------------------------------
Epoch: 249/300 Step: 15/15
total_loss          0.5521
encoder_mse         0.0009
decoder_mse         0.3676
ber_loss            0.3676
----------------------------------------
Epoch 249 training duration 10.32 sec
----------------------------------------
Running validation for epoch 249/300
total_loss          0.7575
encoder_mse         0.0011
decoder_mse         0.5045
ber_loss            0.5045
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-249.pyt
Saving checkpoint done.

Starting epoch 250/300
Batch size = 32
Steps in epoch = 15
Epoch: 250/300 Step: 10/15
total_loss          0.5188
encoder_mse         0.0009
decoder_mse         0.3454
ber_loss            0.3454
----------------------------------------
Epoch: 250/300 Step: 15/15
total_loss          0.4967
encoder_mse         0.0009
decoder_mse         0.3307
ber_loss            0.3307
----------------------------------------
Epoch 250 training duration 10.03 sec
----------------------------------------
Running validation for epoch 250/300
total_loss          0.6642
encoder_mse         0.0011
decoder_mse         0.4423
ber_loss            0.4423
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-250.pyt
Saving checkpoint done.

Starting epoch 251/300
Batch size = 32
Steps in epoch = 15
Epoch: 251/300 Step: 10/15
total_loss          0.4504
encoder_mse         0.0009
decoder_mse         0.2998
ber_loss            0.2998
----------------------------------------
Epoch: 251/300 Step: 15/15
total_loss          0.5485
encoder_mse         0.0009
decoder_mse         0.3652
ber_loss            0.3652
----------------------------------------
Epoch 251 training duration 10.53 sec
----------------------------------------
Running validation for epoch 251/300
total_loss          0.4723
encoder_mse         0.0011
decoder_mse         0.3143
ber_loss            0.3143
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-251.pyt
Saving checkpoint done.

Starting epoch 252/300
Batch size = 32
Steps in epoch = 15
Epoch: 252/300 Step: 10/15
total_loss          0.5298
encoder_mse         0.0010
decoder_mse         0.3527
ber_loss            0.3527
----------------------------------------
Epoch: 252/300 Step: 15/15
total_loss          0.5035
encoder_mse         0.0010
decoder_mse         0.3352
ber_loss            0.3352
----------------------------------------
Epoch 252 training duration 10.28 sec
----------------------------------------
Running validation for epoch 252/300
total_loss          0.6543
encoder_mse         0.0011
decoder_mse         0.4357
ber_loss            0.4357
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-252.pyt
Saving checkpoint done.

Starting epoch 253/300
Batch size = 32
Steps in epoch = 15
Epoch: 253/300 Step: 10/15
total_loss          0.6001
encoder_mse         0.0009
decoder_mse         0.3996
ber_loss            0.3996
----------------------------------------
Epoch: 253/300 Step: 15/15
total_loss          0.6019
encoder_mse         0.0009
decoder_mse         0.4008
ber_loss            0.4008
----------------------------------------
Epoch 253 training duration 10.25 sec
----------------------------------------
Running validation for epoch 253/300
total_loss          0.2780
encoder_mse         0.0011
decoder_mse         0.1848
ber_loss            0.1848
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-253.pyt
Saving checkpoint done.

Starting epoch 254/300
Batch size = 32
Steps in epoch = 15
Epoch: 254/300 Step: 10/15
total_loss          0.6013
encoder_mse         0.0010
decoder_mse         0.4004
ber_loss            0.4004
----------------------------------------
Epoch: 254/300 Step: 15/15
total_loss          0.6538
encoder_mse         0.0010
decoder_mse         0.4354
ber_loss            0.4354
----------------------------------------
Epoch 254 training duration 10.33 sec
----------------------------------------
Running validation for epoch 254/300
total_loss          0.6614
encoder_mse         0.0011
decoder_mse         0.4404
ber_loss            0.4404
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-254.pyt
Saving checkpoint done.

Starting epoch 255/300
Batch size = 32
Steps in epoch = 15
Epoch: 255/300 Step: 10/15
total_loss          0.5233
encoder_mse         0.0010
decoder_mse         0.3484
ber_loss            0.3484
----------------------------------------
Epoch: 255/300 Step: 15/15
total_loss          0.6019
encoder_mse         0.0009
decoder_mse         0.4008
ber_loss            0.4008
----------------------------------------
Epoch 255 training duration 9.91 sec
----------------------------------------
Running validation for epoch 255/300
total_loss          0.6617
encoder_mse         0.0011
decoder_mse         0.4406
ber_loss            0.4406
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-255.pyt
Saving checkpoint done.

Starting epoch 256/300
Batch size = 32
Steps in epoch = 15
Epoch: 256/300 Step: 10/15
total_loss          0.6035
encoder_mse         0.0009
decoder_mse         0.4019
ber_loss            0.4019
----------------------------------------
Epoch: 256/300 Step: 15/15
total_loss          0.6031
encoder_mse         0.0009
decoder_mse         0.4016
ber_loss            0.4016
----------------------------------------
Epoch 256 training duration 9.90 sec
----------------------------------------
Running validation for epoch 256/300
total_loss          0.2840
encoder_mse         0.0011
decoder_mse         0.1888
ber_loss            0.1888
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-256.pyt
Saving checkpoint done.

Starting epoch 257/300
Batch size = 32
Steps in epoch = 15
Epoch: 257/300 Step: 10/15
total_loss          0.6729
encoder_mse         0.0009
decoder_mse         0.4482
ber_loss            0.4482
----------------------------------------
Epoch: 257/300 Step: 15/15
total_loss          0.6000
encoder_mse         0.0009
decoder_mse         0.3996
ber_loss            0.3996
----------------------------------------
Epoch 257 training duration 10.07 sec
----------------------------------------
Running validation for epoch 257/300
total_loss          0.5641
encoder_mse         0.0011
decoder_mse         0.3755
ber_loss            0.3755
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-257.pyt
Saving checkpoint done.

Starting epoch 258/300
Batch size = 32
Steps in epoch = 15
Epoch: 258/300 Step: 10/15
total_loss          0.7520
encoder_mse         0.0010
decoder_mse         0.5009
ber_loss            0.5009
----------------------------------------
Epoch: 258/300 Step: 15/15
total_loss          0.7027
encoder_mse         0.0010
decoder_mse         0.4680
ber_loss            0.4680
----------------------------------------
Epoch 258 training duration 10.24 sec
----------------------------------------
Running validation for epoch 258/300
total_loss          0.5584
encoder_mse         0.0011
decoder_mse         0.3717
ber_loss            0.3717
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-258.pyt
Saving checkpoint done.

Starting epoch 259/300
Batch size = 32
Steps in epoch = 15
Epoch: 259/300 Step: 10/15
total_loss          0.6009
encoder_mse         0.0009
decoder_mse         0.4002
ber_loss            0.4002
----------------------------------------
Epoch: 259/300 Step: 15/15
total_loss          0.5504
encoder_mse         0.0009
decoder_mse         0.3665
ber_loss            0.3665
----------------------------------------
Epoch 259 training duration 10.31 sec
----------------------------------------
Running validation for epoch 259/300
total_loss          0.5671
encoder_mse         0.0011
decoder_mse         0.3776
ber_loss            0.3776
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-259.pyt
Saving checkpoint done.

Starting epoch 260/300
Batch size = 32
Steps in epoch = 15
Epoch: 260/300 Step: 10/15
total_loss          0.6807
encoder_mse         0.0009
decoder_mse         0.4534
ber_loss            0.4534
----------------------------------------
Epoch: 260/300 Step: 15/15
total_loss          0.6025
encoder_mse         0.0009
decoder_mse         0.4013
ber_loss            0.4013
----------------------------------------
Epoch 260 training duration 10.45 sec
----------------------------------------
Running validation for epoch 260/300
total_loss          0.5603
encoder_mse         0.0011
decoder_mse         0.3730
ber_loss            0.3730
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-260.pyt
Saving checkpoint done.

Starting epoch 261/300
Batch size = 32
Steps in epoch = 15
Epoch: 261/300 Step: 10/15
total_loss          0.4537
encoder_mse         0.0009
decoder_mse         0.3020
ber_loss            0.3020
----------------------------------------
Epoch: 261/300 Step: 15/15
total_loss          0.4019
encoder_mse         0.0009
decoder_mse         0.2675
ber_loss            0.2675
----------------------------------------
Epoch 261 training duration 10.20 sec
----------------------------------------
Running validation for epoch 261/300
total_loss          0.6606
encoder_mse         0.0011
decoder_mse         0.4399
ber_loss            0.4399
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-261.pyt
Saving checkpoint done.

Starting epoch 262/300
Batch size = 32
Steps in epoch = 15
Epoch: 262/300 Step: 10/15
total_loss          0.6009
encoder_mse         0.0009
decoder_mse         0.4002
ber_loss            0.4002
----------------------------------------
Epoch: 262/300 Step: 15/15
total_loss          0.6020
encoder_mse         0.0009
decoder_mse         0.4009
ber_loss            0.4009
----------------------------------------
Epoch 262 training duration 10.14 sec
----------------------------------------
Running validation for epoch 262/300
total_loss          0.6515
encoder_mse         0.0011
decoder_mse         0.4338
ber_loss            0.4338
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-262.pyt
Saving checkpoint done.

Starting epoch 263/300
Batch size = 32
Steps in epoch = 15
Epoch: 263/300 Step: 10/15
total_loss          0.6724
encoder_mse         0.0009
decoder_mse         0.4478
ber_loss            0.4478
----------------------------------------
Epoch: 263/300 Step: 15/15
total_loss          0.6006
encoder_mse         0.0009
decoder_mse         0.4000
ber_loss            0.4000
----------------------------------------
Epoch 263 training duration 10.37 sec
----------------------------------------
Running validation for epoch 263/300
total_loss          0.4668
encoder_mse         0.0011
decoder_mse         0.3107
ber_loss            0.3107
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-263.pyt
Saving checkpoint done.

Starting epoch 264/300
Batch size = 32
Steps in epoch = 15
Epoch: 264/300 Step: 10/15
total_loss          0.5975
encoder_mse         0.0010
decoder_mse         0.3979
ber_loss            0.3979
----------------------------------------
Epoch: 264/300 Step: 15/15
total_loss          0.6019
encoder_mse         0.0010
decoder_mse         0.4008
ber_loss            0.4008
----------------------------------------
Epoch 264 training duration 9.91 sec
----------------------------------------
Running validation for epoch 264/300
total_loss          0.6552
encoder_mse         0.0011
decoder_mse         0.4363
ber_loss            0.4363
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-264.pyt
Saving checkpoint done.

Starting epoch 265/300
Batch size = 32
Steps in epoch = 15
Epoch: 265/300 Step: 10/15
total_loss          0.6001
encoder_mse         0.0010
decoder_mse         0.3996
ber_loss            0.3996
----------------------------------------
Epoch: 265/300 Step: 15/15
total_loss          0.6490
encoder_mse         0.0010
decoder_mse         0.4322
ber_loss            0.4322
----------------------------------------
Epoch 265 training duration 10.06 sec
----------------------------------------
Running validation for epoch 265/300
total_loss          0.5657
encoder_mse         0.0011
decoder_mse         0.3766
ber_loss            0.3766
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-265.pyt
Saving checkpoint done.

Starting epoch 266/300
Batch size = 32
Steps in epoch = 15
Epoch: 266/300 Step: 10/15
total_loss          0.6734
encoder_mse         0.0009
decoder_mse         0.4485
ber_loss            0.4485
----------------------------------------
Epoch: 266/300 Step: 15/15
total_loss          0.6010
encoder_mse         0.0009
decoder_mse         0.4002
ber_loss            0.4002
----------------------------------------
Epoch 266 training duration 10.38 sec
----------------------------------------
Running validation for epoch 266/300
total_loss          0.5610
encoder_mse         0.0011
decoder_mse         0.3735
ber_loss            0.3735
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-266.pyt
Saving checkpoint done.

Starting epoch 267/300
Batch size = 32
Steps in epoch = 15
Epoch: 267/300 Step: 10/15
total_loss          0.6753
encoder_mse         0.0010
decoder_mse         0.4498
ber_loss            0.4498
----------------------------------------
Epoch: 267/300 Step: 15/15
total_loss          0.6493
encoder_mse         0.0009
decoder_mse         0.4325
ber_loss            0.4325
----------------------------------------
Epoch 267 training duration 9.88 sec
----------------------------------------
Running validation for epoch 267/300
total_loss          0.5586
encoder_mse         0.0011
decoder_mse         0.3719
ber_loss            0.3719
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-267.pyt
Saving checkpoint done.

Starting epoch 268/300
Batch size = 32
Steps in epoch = 15
Epoch: 268/300 Step: 10/15
total_loss          0.6783
encoder_mse         0.0009
decoder_mse         0.4518
ber_loss            0.4518
----------------------------------------
Epoch: 268/300 Step: 15/15
total_loss          0.6017
encoder_mse         0.0009
decoder_mse         0.4007
ber_loss            0.4007
----------------------------------------
Epoch 268 training duration 10.34 sec
----------------------------------------
Running validation for epoch 268/300
total_loss          0.7546
encoder_mse         0.0011
decoder_mse         0.5025
ber_loss            0.5025
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-268.pyt
Saving checkpoint done.

Starting epoch 269/300
Batch size = 32
Steps in epoch = 15
Epoch: 269/300 Step: 10/15
total_loss          0.6018
encoder_mse         0.0008
decoder_mse         0.4008
ber_loss            0.4008
----------------------------------------
Epoch: 269/300 Step: 15/15
total_loss          0.6053
encoder_mse         0.0009
decoder_mse         0.4031
ber_loss            0.4031
----------------------------------------
Epoch 269 training duration 10.08 sec
----------------------------------------
Running validation for epoch 269/300
total_loss          0.7526
encoder_mse         0.0011
decoder_mse         0.5012
ber_loss            0.5012
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-269.pyt
Saving checkpoint done.

Starting epoch 270/300
Batch size = 32
Steps in epoch = 15
Epoch: 270/300 Step: 10/15
total_loss          0.6725
encoder_mse         0.0009
decoder_mse         0.4479
ber_loss            0.4479
----------------------------------------
Epoch: 270/300 Step: 15/15
total_loss          0.6006
encoder_mse         0.0010
decoder_mse         0.4000
ber_loss            0.4000
----------------------------------------
Epoch 270 training duration 9.95 sec
----------------------------------------
Running validation for epoch 270/300
total_loss          0.5694
encoder_mse         0.0011
decoder_mse         0.3791
ber_loss            0.3791
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-270.pyt
Saving checkpoint done.

Starting epoch 271/300
Batch size = 32
Steps in epoch = 15
Epoch: 271/300 Step: 10/15
total_loss          0.7511
encoder_mse         0.0009
decoder_mse         0.5003
ber_loss            0.5003
----------------------------------------
Epoch: 271/300 Step: 15/15
total_loss          0.7537
encoder_mse         0.0009
decoder_mse         0.5020
ber_loss            0.5020
----------------------------------------
Epoch 271 training duration 10.45 sec
----------------------------------------
Running validation for epoch 271/300
total_loss          0.6541
encoder_mse         0.0011
decoder_mse         0.4356
ber_loss            0.4356
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-271.pyt
Saving checkpoint done.

Starting epoch 272/300
Batch size = 32
Steps in epoch = 15
Epoch: 272/300 Step: 10/15
total_loss          0.5979
encoder_mse         0.0009
decoder_mse         0.3982
ber_loss            0.3982
----------------------------------------
Epoch: 272/300 Step: 15/15
total_loss          0.6497
encoder_mse         0.0009
decoder_mse         0.4327
ber_loss            0.4327
----------------------------------------
Epoch 272 training duration 10.18 sec
----------------------------------------
Running validation for epoch 272/300
total_loss          0.5669
encoder_mse         0.0011
decoder_mse         0.3774
ber_loss            0.3774
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-272.pyt
Saving checkpoint done.

Starting epoch 273/300
Batch size = 32
Steps in epoch = 15
Epoch: 273/300 Step: 10/15
total_loss          0.5988
encoder_mse         0.0010
decoder_mse         0.3988
ber_loss            0.3988
----------------------------------------
Epoch: 273/300 Step: 15/15
total_loss          0.6511
encoder_mse         0.0009
decoder_mse         0.4336
ber_loss            0.4336
----------------------------------------
Epoch 273 training duration 9.95 sec
----------------------------------------
Running validation for epoch 273/300
total_loss          0.5614
encoder_mse         0.0011
decoder_mse         0.3737
ber_loss            0.3737
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-273.pyt
Saving checkpoint done.

Starting epoch 274/300
Batch size = 32
Steps in epoch = 15
Epoch: 274/300 Step: 10/15
total_loss          0.6771
encoder_mse         0.0010
decoder_mse         0.4510
ber_loss            0.4510
----------------------------------------
Epoch: 274/300 Step: 15/15
total_loss          0.6528
encoder_mse         0.0010
decoder_mse         0.4347
ber_loss            0.4347
----------------------------------------
Epoch 274 training duration 10.36 sec
----------------------------------------
Running validation for epoch 274/300
total_loss          0.4713
encoder_mse         0.0011
decoder_mse         0.3137
ber_loss            0.3137
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-274.pyt
Saving checkpoint done.

Starting epoch 275/300
Batch size = 32
Steps in epoch = 15
Epoch: 275/300 Step: 10/15
total_loss          0.4501
encoder_mse         0.0009
decoder_mse         0.2997
ber_loss            0.2997
----------------------------------------
Epoch: 275/300 Step: 15/15
total_loss          0.5019
encoder_mse         0.0009
decoder_mse         0.3341
ber_loss            0.3341
----------------------------------------
Epoch 275 training duration 10.09 sec
----------------------------------------
Running validation for epoch 275/300
total_loss          0.5652
encoder_mse         0.0011
decoder_mse         0.3763
ber_loss            0.3763
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-275.pyt
Saving checkpoint done.

Starting epoch 276/300
Batch size = 32
Steps in epoch = 15
Epoch: 276/300 Step: 10/15
total_loss          0.6020
encoder_mse         0.0009
decoder_mse         0.4009
ber_loss            0.4009
----------------------------------------
Epoch: 276/300 Step: 15/15
total_loss          0.6517
encoder_mse         0.0009
decoder_mse         0.4340
ber_loss            0.4340
----------------------------------------
Epoch 276 training duration 10.35 sec
----------------------------------------
Running validation for epoch 276/300
total_loss          0.5579
encoder_mse         0.0011
decoder_mse         0.3714
ber_loss            0.3714
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-276.pyt
Saving checkpoint done.

Starting epoch 277/300
Batch size = 32
Steps in epoch = 15
Epoch: 277/300 Step: 10/15
total_loss          0.4473
encoder_mse         0.0009
decoder_mse         0.2978
ber_loss            0.2978
----------------------------------------
Epoch: 277/300 Step: 15/15
total_loss          0.5496
encoder_mse         0.0009
decoder_mse         0.3660
ber_loss            0.3660
----------------------------------------
Epoch 277 training duration 10.29 sec
----------------------------------------
Running validation for epoch 277/300
total_loss          0.6638
encoder_mse         0.0011
decoder_mse         0.4420
ber_loss            0.4420
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-277.pyt
Saving checkpoint done.

Starting epoch 278/300
Batch size = 32
Steps in epoch = 15
Epoch: 278/300 Step: 10/15
total_loss          0.5298
encoder_mse         0.0009
decoder_mse         0.3528
ber_loss            0.3528
----------------------------------------
Epoch: 278/300 Step: 15/15
total_loss          0.5552
encoder_mse         0.0009
decoder_mse         0.3697
ber_loss            0.3697
----------------------------------------
Epoch 278 training duration 9.73 sec
----------------------------------------
Running validation for epoch 278/300
total_loss          0.4678
encoder_mse         0.0011
decoder_mse         0.3114
ber_loss            0.3114
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-278.pyt
Saving checkpoint done.

Starting epoch 279/300
Batch size = 32
Steps in epoch = 15
Epoch: 279/300 Step: 10/15
total_loss          0.5992
encoder_mse         0.0010
decoder_mse         0.3990
ber_loss            0.3990
----------------------------------------
Epoch: 279/300 Step: 15/15
total_loss          0.5993
encoder_mse         0.0010
decoder_mse         0.3991
ber_loss            0.3991
----------------------------------------
Epoch 279 training duration 10.38 sec
----------------------------------------
Running validation for epoch 279/300
total_loss          0.5635
encoder_mse         0.0011
decoder_mse         0.3751
ber_loss            0.3751
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-279.pyt
Saving checkpoint done.

Starting epoch 280/300
Batch size = 32
Steps in epoch = 15
Epoch: 280/300 Step: 10/15
total_loss          0.5258
encoder_mse         0.0009
decoder_mse         0.3501
ber_loss            0.3501
----------------------------------------
Epoch: 280/300 Step: 15/15
total_loss          0.5497
encoder_mse         0.0009
decoder_mse         0.3661
ber_loss            0.3661
----------------------------------------
Epoch 280 training duration 10.08 sec
----------------------------------------
Running validation for epoch 280/300
total_loss          0.5620
encoder_mse         0.0011
decoder_mse         0.3742
ber_loss            0.3742
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-280.pyt
Saving checkpoint done.

Starting epoch 281/300
Batch size = 32
Steps in epoch = 15
Epoch: 281/300 Step: 10/15
total_loss          0.4528
encoder_mse         0.0009
decoder_mse         0.3014
ber_loss            0.3014
----------------------------------------
Epoch: 281/300 Step: 15/15
total_loss          0.5521
encoder_mse         0.0009
decoder_mse         0.3676
ber_loss            0.3676
----------------------------------------
Epoch 281 training duration 9.89 sec
----------------------------------------
Running validation for epoch 281/300
total_loss          0.2818
encoder_mse         0.0011
decoder_mse         0.1874
ber_loss            0.1874
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-281.pyt
Saving checkpoint done.

Starting epoch 282/300
Batch size = 32
Steps in epoch = 15
Epoch: 282/300 Step: 10/15
total_loss          0.7505
encoder_mse         0.0009
decoder_mse         0.4999
ber_loss            0.4999
----------------------------------------
Epoch: 282/300 Step: 15/15
total_loss          0.7503
encoder_mse         0.0009
decoder_mse         0.4998
ber_loss            0.4998
----------------------------------------
Epoch 282 training duration 10.43 sec
----------------------------------------
Running validation for epoch 282/300
total_loss          0.6575
encoder_mse         0.0011
decoder_mse         0.4378
ber_loss            0.4378
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-282.pyt
Saving checkpoint done.

Starting epoch 283/300
Batch size = 32
Steps in epoch = 15
Epoch: 283/300 Step: 10/15
total_loss          0.7482
encoder_mse         0.0009
decoder_mse         0.4983
ber_loss            0.4983
----------------------------------------
Epoch: 283/300 Step: 15/15
total_loss          0.7000
encoder_mse         0.0009
decoder_mse         0.4663
ber_loss            0.4663
----------------------------------------
Epoch 283 training duration 10.48 sec
----------------------------------------
Running validation for epoch 283/300
total_loss          0.6600
encoder_mse         0.0011
decoder_mse         0.4395
ber_loss            0.4395
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-283.pyt
Saving checkpoint done.

Starting epoch 284/300
Batch size = 32
Steps in epoch = 15
Epoch: 284/300 Step: 10/15
total_loss          0.6019
encoder_mse         0.0009
decoder_mse         0.4008
ber_loss            0.4008
----------------------------------------
Epoch: 284/300 Step: 15/15
total_loss          0.5507
encoder_mse         0.0009
decoder_mse         0.3667
ber_loss            0.3667
----------------------------------------
Epoch 284 training duration 10.15 sec
----------------------------------------
Running validation for epoch 284/300
total_loss          0.6592
encoder_mse         0.0011
decoder_mse         0.4389
ber_loss            0.4389
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-284.pyt
Saving checkpoint done.

Starting epoch 285/300
Batch size = 32
Steps in epoch = 15
Epoch: 285/300 Step: 10/15
total_loss          0.6774
encoder_mse         0.0010
decoder_mse         0.4511
ber_loss            0.4511
----------------------------------------
Epoch: 285/300 Step: 15/15
total_loss          0.6501
encoder_mse         0.0010
decoder_mse         0.4329
ber_loss            0.4329
----------------------------------------
Epoch 285 training duration 10.11 sec
----------------------------------------
Running validation for epoch 285/300
total_loss          0.6543
encoder_mse         0.0011
decoder_mse         0.4357
ber_loss            0.4357
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-285.pyt
Saving checkpoint done.

Starting epoch 286/300
Batch size = 32
Steps in epoch = 15
Epoch: 286/300 Step: 10/15
total_loss          0.5257
encoder_mse         0.0009
decoder_mse         0.3500
ber_loss            0.3500
----------------------------------------
Epoch: 286/300 Step: 15/15
total_loss          0.5990
encoder_mse         0.0009
decoder_mse         0.3989
ber_loss            0.3989
----------------------------------------
Epoch 286 training duration 10.65 sec
----------------------------------------
Running validation for epoch 286/300
total_loss          0.6566
encoder_mse         0.0011
decoder_mse         0.4372
ber_loss            0.4372
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-286.pyt
Saving checkpoint done.

Starting epoch 287/300
Batch size = 32
Steps in epoch = 15
Epoch: 287/300 Step: 10/15
total_loss          0.7489
encoder_mse         0.0010
decoder_mse         0.4989
ber_loss            0.4989
----------------------------------------
Epoch: 287/300 Step: 15/15
total_loss          0.7013
encoder_mse         0.0010
decoder_mse         0.4671
ber_loss            0.4671
----------------------------------------
Epoch 287 training duration 10.30 sec
----------------------------------------
Running validation for epoch 287/300
total_loss          0.6535
encoder_mse         0.0011
decoder_mse         0.4352
ber_loss            0.4352
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-287.pyt
Saving checkpoint done.

Starting epoch 288/300
Batch size = 32
Steps in epoch = 15
Epoch: 288/300 Step: 10/15
total_loss          0.5242
encoder_mse         0.0010
decoder_mse         0.3490
ber_loss            0.3490
----------------------------------------
Epoch: 288/300 Step: 15/15
total_loss          0.5001
encoder_mse         0.0010
decoder_mse         0.3329
ber_loss            0.3329
----------------------------------------
Epoch 288 training duration 10.05 sec
----------------------------------------
Running validation for epoch 288/300
total_loss          0.4700
encoder_mse         0.0011
decoder_mse         0.3128
ber_loss            0.3128
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-288.pyt
Saving checkpoint done.

Starting epoch 289/300
Batch size = 32
Steps in epoch = 15
Epoch: 289/300 Step: 10/15
total_loss          0.3711
encoder_mse         0.0009
decoder_mse         0.2470
ber_loss            0.2470
----------------------------------------
Epoch: 289/300 Step: 15/15
total_loss          0.4476
encoder_mse         0.0009
decoder_mse         0.2979
ber_loss            0.2979
----------------------------------------
Epoch 289 training duration 10.36 sec
----------------------------------------
Running validation for epoch 289/300
total_loss          0.6604
encoder_mse         0.0011
decoder_mse         0.4397
ber_loss            0.4397
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-289.pyt
Saving checkpoint done.

Starting epoch 290/300
Batch size = 32
Steps in epoch = 15
Epoch: 290/300 Step: 10/15
total_loss          0.5289
encoder_mse         0.0010
decoder_mse         0.3521
ber_loss            0.3521
----------------------------------------
Epoch: 290/300 Step: 15/15
total_loss          0.6046
encoder_mse         0.0009
decoder_mse         0.4026
ber_loss            0.4026
----------------------------------------
Epoch 290 training duration 10.05 sec
----------------------------------------
Running validation for epoch 290/300
total_loss          0.5625
encoder_mse         0.0011
decoder_mse         0.3745
ber_loss            0.3745
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-290.pyt
Saving checkpoint done.

Starting epoch 291/300
Batch size = 32
Steps in epoch = 15
Epoch: 291/300 Step: 10/15
total_loss          0.5221
encoder_mse         0.0009
decoder_mse         0.3477
ber_loss            0.3477
----------------------------------------
Epoch: 291/300 Step: 15/15
total_loss          0.4985
encoder_mse         0.0009
decoder_mse         0.3319
ber_loss            0.3319
----------------------------------------
Epoch 291 training duration 10.55 sec
----------------------------------------
Running validation for epoch 291/300
total_loss          0.4717
encoder_mse         0.0011
decoder_mse         0.3140
ber_loss            0.3140
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-291.pyt
Saving checkpoint done.

Starting epoch 292/300
Batch size = 32
Steps in epoch = 15
Epoch: 292/300 Step: 10/15
total_loss          0.6810
encoder_mse         0.0009
decoder_mse         0.4536
ber_loss            0.4536
----------------------------------------
Epoch: 292/300 Step: 15/15
total_loss          0.6048
encoder_mse         0.0009
decoder_mse         0.4028
ber_loss            0.4028
----------------------------------------
Epoch 292 training duration 10.21 sec
----------------------------------------
Running validation for epoch 292/300
total_loss          0.5644
encoder_mse         0.0011
decoder_mse         0.3757
ber_loss            0.3757
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-292.pyt
Saving checkpoint done.

Starting epoch 293/300
Batch size = 32
Steps in epoch = 15
Epoch: 293/300 Step: 10/15
total_loss          0.6794
encoder_mse         0.0010
decoder_mse         0.4525
ber_loss            0.4525
----------------------------------------
Epoch: 293/300 Step: 15/15
total_loss          0.6035
encoder_mse         0.0010
decoder_mse         0.4019
ber_loss            0.4019
----------------------------------------
Epoch 293 training duration 10.02 sec
----------------------------------------
Running validation for epoch 293/300
total_loss          0.5591
encoder_mse         0.0011
decoder_mse         0.3722
ber_loss            0.3722
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-293.pyt
Saving checkpoint done.

Starting epoch 294/300
Batch size = 32
Steps in epoch = 15
Epoch: 294/300 Step: 10/15
total_loss          0.6732
encoder_mse         0.0009
decoder_mse         0.4484
ber_loss            0.4484
----------------------------------------
Epoch: 294/300 Step: 15/15
total_loss          0.5952
encoder_mse         0.0009
decoder_mse         0.3964
ber_loss            0.3964
----------------------------------------
Epoch 294 training duration 10.58 sec
----------------------------------------
Running validation for epoch 294/300
total_loss          0.5632
encoder_mse         0.0011
decoder_mse         0.3750
ber_loss            0.3750
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-294.pyt
Saving checkpoint done.

Starting epoch 295/300
Batch size = 32
Steps in epoch = 15
Epoch: 295/300 Step: 10/15
total_loss          0.6755
encoder_mse         0.0009
decoder_mse         0.4499
ber_loss            0.4499
----------------------------------------
Epoch: 295/300 Step: 15/15
total_loss          0.6520
encoder_mse         0.0009
decoder_mse         0.4343
ber_loss            0.4343
----------------------------------------
Epoch 295 training duration 10.15 sec
----------------------------------------
Running validation for epoch 295/300
total_loss          0.4660
encoder_mse         0.0011
decoder_mse         0.3102
ber_loss            0.3102
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-295.pyt
Saving checkpoint done.

Starting epoch 296/300
Batch size = 32
Steps in epoch = 15
Epoch: 296/300 Step: 10/15
total_loss          0.6021
encoder_mse         0.0009
decoder_mse         0.4010
ber_loss            0.4010
----------------------------------------
Epoch: 296/300 Step: 15/15
total_loss          0.5518
encoder_mse         0.0009
decoder_mse         0.3674
ber_loss            0.3674
----------------------------------------
Epoch 296 training duration 10.30 sec
----------------------------------------
Running validation for epoch 296/300
total_loss          0.4723
encoder_mse         0.0011
decoder_mse         0.3143
ber_loss            0.3143
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-296.pyt
Saving checkpoint done.

Starting epoch 297/300
Batch size = 32
Steps in epoch = 15
Epoch: 297/300 Step: 10/15
total_loss          0.4531
encoder_mse         0.0010
decoder_mse         0.3016
ber_loss            0.3016
----------------------------------------
Epoch: 297/300 Step: 15/15
total_loss          0.4530
encoder_mse         0.0009
decoder_mse         0.3015
ber_loss            0.3015
----------------------------------------
Epoch 297 training duration 10.31 sec
----------------------------------------
Running validation for epoch 297/300
total_loss          0.6561
encoder_mse         0.0011
decoder_mse         0.4369
ber_loss            0.4369
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-297.pyt
Saving checkpoint done.

Starting epoch 298/300
Batch size = 32
Steps in epoch = 15
Epoch: 298/300 Step: 10/15
total_loss          0.6057
encoder_mse         0.0009
decoder_mse         0.4034
ber_loss            0.4034
----------------------------------------
Epoch: 298/300 Step: 15/15
total_loss          0.6043
encoder_mse         0.0009
decoder_mse         0.4024
ber_loss            0.4024
----------------------------------------
Epoch 298 training duration 9.83 sec
----------------------------------------
Running validation for epoch 298/300
total_loss          0.6550
encoder_mse         0.0011
decoder_mse         0.4361
ber_loss            0.4361
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-298.pyt
Saving checkpoint done.

Starting epoch 299/300
Batch size = 32
Steps in epoch = 15
Epoch: 299/300 Step: 10/15
total_loss          0.6060
encoder_mse         0.0009
decoder_mse         0.4036
ber_loss            0.4036
----------------------------------------
Epoch: 299/300 Step: 15/15
total_loss          0.6051
encoder_mse         0.0009
decoder_mse         0.4030
ber_loss            0.4030
----------------------------------------
Epoch 299 training duration 10.50 sec
----------------------------------------
Running validation for epoch 299/300
total_loss          0.5683
encoder_mse         0.0011
decoder_mse         0.3783
ber_loss            0.3783
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-299.pyt
Saving checkpoint done.

Starting epoch 300/300
Batch size = 32
Steps in epoch = 15
Epoch: 300/300 Step: 10/15
total_loss          0.6053
encoder_mse         0.0009
decoder_mse         0.4031
ber_loss            0.4031
----------------------------------------
Epoch: 300/300 Step: 15/15
total_loss          0.6035
encoder_mse         0.0010
decoder_mse         0.4019
ber_loss            0.4019
----------------------------------------
Epoch 300 training duration 9.97 sec
----------------------------------------
Running validation for epoch 300/300
total_loss          0.4710
encoder_mse         0.0011
decoder_mse         0.3135
ber_loss            0.3135
----------------------------------------
Saving checkpoint to ./runs/celebhq-rebuttal 2025.01.29--21-14-59/checkpoints/celebhq-rebuttal--epoch-300.pyt
Saving checkpoint done.
